{
  "hash": "840d6328931bf63c83813c7807f1576c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 3\\nDecomposition\"\nformat: \n  revealjs:\n    output-file: \"3-decomp.html\"\n  html:\n    output-file: \"3-decomp_o.html\"\nlogo: \"../img/favicon.png\"\n---\n\n\n\n\n## Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(purrr)\nlibrary(gganimate)\nlibrary(latex2exp)\nlibrary(fpp3)\n```\n:::\n\n\n\n\n# Transformations and adjustments\n\n## Per capita adjustments\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Country == \"Australia\") |>\n  autoplot(GDP)\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/gdp-per-capita-1.png){width=960}\n:::\n:::\n\n\n\n\n## Per capita adjustments\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Country == \"Australia\") |>\n  autoplot(GDP / Population)\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/gdp-per-capita2-1.png){width=960}\n:::\n:::\n\n\n\n\n## You Try!\n\n:::{.question}\nConsider the GDP information in `global_economy`. Plot the GDP per capita for each country over time. Which country has the highest GDP per capita? How has this changed over time? -->\n:::\n\n## Inflation adjustments\n\n- Data which are affected by the value of money are best adjusted before modelling. \n - For example, the average cost of a new house will have increased over the last few decades due to inflation. A \\$200,000 house this year is not the same as a \\$200,000 house twenty years ago. \n\n## Inflation adjustments {.smaller}\n\n- To make these adjustments, a price index is used. If $z_t$ denotes the price index and $y_t$ denotes the original house price in year $t$, then \n\n. . .\n\n$$x_t=y_t/z_t \\cdot z_{2000}$$\n\ngives the adjusted house price at year 2000 dollar values. \n\n- Price indexes are often constructed by government agencies. For consumer goods, a common price index is the Consumer Price Index (or CPI).\n\n## Inflation adjustments\n\n:::{.panel-tabset}\n\n### Code \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_newspaper_retail <- readr::read_csv('data/aus_newspaper_retail.csv')\n# Turnover:\tRetail turnover in $Million AUD\n\naus_newspaper_retail <- aus_newspaper_retail |>\n  select(Year,Turnover,name) |> # Picks out these 3 columns/variables\n  group_by(Year,name) |> # Tells are to now calculate by groups by year and name\n  summarise(sum_Turnover = sum(Turnover))|> #adds up Turnover for each year and name combination\n  as_tsibble(index = Year, key = \"name\") # Converts to time series\n\naus_newspaper_retail |> autoplot(sum_Turnover) +\n  facet_grid(name ~ ., scales = \"free_y\") + # This will make a grid of plots\n    # with name used to break into multiple plots along the y direction\n  labs(title = \"Turnover: Australian print media industry\", y = \"$AU\")\n```\n:::\n\n\n\n\n\n\n### Plot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n\n\n:::\n\n## Mathematical transformations {.smaller}\n\n\nIf the data show different variation at different levels of the series, then a transformation can be useful.\n\n. . .\n\nDenote original observations as $y_1,\\dots,y_T$ and transformed observations as $w_1, \\dots, w_T$.\n\n. . .\n\n\\underline{Mathematical transformations for stabilizing}\n\n| Function      |                         | Impact        |\n|---------------|-------------------------|---------------|\n| Square root \t| $w_t = \\sqrt{y_t}$    \t| $\\downarrow$ \t|\n| Cube root   \t| $w_t = \\sqrt[3]{y_t}$ \t| Increasing   \t|\n| Logarithm   \t| $w_t = \\log(y_t)$     \t| strength     \t|\n\n\n. . .\n\nLogarithms, in particular, are useful because they are more interpretable: changes in a log value are **relative (percent) changes on the original scale**.\n\n## Mathematical transformations (1/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood <- aus_retail |>\n  filter(Industry == \"Food retailing\") |>\n  summarise(Turnover = sum(Turnover))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-plot-1.png){width=960}\n:::\n:::\n\n\n\n\n## Mathematical transformations (2/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood |> autoplot(sqrt(Turnover)) +\n  labs(y = \"Square root turnover\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-sqrt1-1.png){width=960}\n:::\n:::\n\n\n\n\n## Mathematical transformations (3/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood |> autoplot(Turnover^(1/3)) +\n  labs(y = \"Cube root turnover\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-cbrt-1.png){width=960}\n:::\n:::\n\n\n\n\n## Mathematical transformations (4/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood |> autoplot(log(Turnover)) +\n  labs(y = \"Log turnover\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-log-1.png){width=960}\n:::\n:::\n\n\n\n\n. . .\n\n(log here is the natural log, base $e$)\n\n## Box-Cox transformations {.smaller}\n\nEach of these transformations is close to a member of the\nfamily of \\textbf{Box-Cox transformations}:\n\n$$w_t = \\left\\{\\begin{array}{ll}\n        \\log(y_t),      & \\quad \\lambda = 0; \\\\\n        (sign(y_t)|y_t|^\\lambda-1)/\\lambda ,         & \\quad \\lambda \\ne 0.\n\\end{array}\\right.$$\n\n- Actually the Bickel-Doksum transformation (allowing for $y_t<0$)\n- $\\lambda=1$: (No substantive transformation)\n- $\\lambda=\\frac12$: (Square root plus linear transformation)\n- $\\lambda=0$: (Natural logarithm)\n\n## Box-Cox transformations\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-anim-1.gif)\n:::\n:::\n\n\n\n\n## Box-Cox transformations {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood |>\n  features(Turnover, features = guerrero)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 1\n  lambda_guerrero\n            <dbl>\n1          0.0895\n```\n\n\n:::\n:::\n\n\n\n\n- This attempts to balance the seasonal fluctuations and random variation across the series.\n- Always check the results.\n- A low value of $\\lambda$ can give extremely large prediction intervals.\n\n## Box-Cox transformations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfood |> autoplot(box_cox(Turnover, 0.0524)) +\n  labs(y = \"Box-Cox transformed turnover\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/food-bc-1.png){width=960}\n:::\n:::\n\n\n\n\n## Transformations {.smaller}\n\n\n\n- Often no transformation needed.\n- Simple transformations are easier to explain and work well enough.\n- Transformations can have very large effect on PI.\n- If some data are zero or negative, then use $\\lambda>0$.\n- `log1p()` can also be useful for data with zeros.\n- Choosing logs is a simple way to force forecasts to be positive\n- Transformations must be reversed to obtain forecasts on the original scale. (Handled automatically by `fable`.)\n\n\n## You Try! {.smaller}\n\n1. For the following series, find an appropriate transformation in order to stabilise the variance.\n\n    - United States GDP from `global_economy`\n    - Slaughter of Victorian “Bulls, bullocks and steers” in `aus_livestock`\n    - Victorian Electricity Demand from `vic_elec`.\n    - Gas production from `aus_production`\n\n2. Why is a Box-Cox transformation unhelpful for the `canadian_gas` data?\n\n\n\n\n# Time series components\n\n## Time series patterns {.smaller}\n\n**Recall**\n\nTrend\n:  pattern exists when there is a long-term increase or decrease in the data.\n\nCyclic\n: pattern exists when data exhibit rises and falls that are *not of fixed period* (duration usually of at least 2 years).\n\nSeasonal\n: pattern exists when a series is influenced by seasonal factors (e.g., the quarter of the year, the month, or day of the week).\n\n## Time series decomposition {.smaller}\n\n$y_t = f(S_t, T_t, R_t)$\n\nwhere $y_t=$, data at period $t$ \n\n$T_t=$, trend-cycle component at period $t$\n\n$S_t=$, seasonal component at period $t$ \n\n$R_t=$,remainder component at period $t$\n\n. . .\n\n**Additive decomposition:** $y_t = S_t + T_t + R_t.$\n\n. . .\n\n**Multiplicative decomposition:** $y_t = S_t \\times T_t \\times R_t.$\n\n## Time series decomposition {.smaller}\n\n  -  Additive model  appropriate if  magnitude of  seasonal fluctuations does not vary with level.\n  -  If seasonal are proportional to level of series, then multiplicative model appropriate.\n  -  Multiplicative decomposition more prevalent with economic series\n  -  Alternative: use a Box-Cox transformation, and then use additive decomposition.\n  -  Logs turn multiplicative relationship into an additive relationship:\n\n. . .\n\n$$y_t = S_t \\times T_t \\times R_t \\quad\\Rightarrow\\quad\n\\log y_t = \\log S_t + \\log T_t + \\log R_t.$$\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment <- us_employment |>\n  filter(year(Month) >= 1990, Title == \"Retail Trade\") |>\n  select(-Series_ID)\nus_retail_employment\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 357 x 3 [1M]\n      Month Title        Employed\n      <mth> <chr>           <dbl>\n 1 1990 Jan Retail Trade   13256.\n 2 1990 Feb Retail Trade   12966.\n 3 1990 Mar Retail Trade   12938.\n 4 1990 Apr Retail Trade   13012.\n 5 1990 May Retail Trade   13108.\n 6 1990 Jun Retail Trade   13183.\n 7 1990 Jul Retail Trade   13170.\n 8 1990 Aug Retail Trade   13160.\n 9 1990 Sep Retail Trade   13113.\n10 1990 Oct Retail Trade   13185.\n# ℹ 347 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  autoplot(Employed) +\n  labs(y=\"Persons (thousands)\", title=\"Total employment in US retail\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/dable1-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  model(stl = STL(Employed))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 1 x 1\n      stl\n  <model>\n1   <STL>\n```\n\n\n:::\n:::\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcmp <- us_retail_employment |>\n  model(stl = STL(Employed))\ncomponents(dcmp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A dable: 357 x 7 [1M]\n# Key:     .model [1]\n# :        Employed = trend + season_year + remainder\n   .model    Month Employed  trend season_year remainder season_adjust\n   <chr>     <mth>    <dbl>  <dbl>       <dbl>     <dbl>         <dbl>\n 1 stl    1990 Jan   13256. 13288.      -33.0      0.836        13289.\n 2 stl    1990 Feb   12966. 13269.     -258.     -44.6          13224.\n 3 stl    1990 Mar   12938. 13250.     -290.     -22.1          13228.\n 4 stl    1990 Apr   13012. 13231.     -220.       1.05         13232.\n 5 stl    1990 May   13108. 13211.     -114.      11.3          13223.\n 6 stl    1990 Jun   13183. 13192.      -24.3     15.5          13207.\n 7 stl    1990 Jul   13170. 13172.      -23.2     21.6          13193.\n 8 stl    1990 Aug   13160. 13151.       -9.52    17.8          13169.\n 9 stl    1990 Sep   13113. 13131.      -39.5     22.0          13153.\n10 stl    1990 Oct   13185. 13110.       61.6     13.2          13124.\n# ℹ 347 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  autoplot(Employed, color='gray') +\n  autolayer(components(dcmp), trend, color='#523178') +\n  labs(y=\"Persons (thousands)\", title=\"Total employment in US retail\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/dable4-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomponents(dcmp) |> autoplot()\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/usretail-stl-1.png){width=960}\n:::\n:::\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomponents(dcmp) |> gg_subseries(season_year)\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/usretail3-1.png){width=960}\n:::\n:::\n\n\n\n\n## Seasonal adjustment\n\n  -  Useful by-product of decomposition:  an easy way to calculate seasonally adjusted data.\n  -  Additive decomposition: seasonally adjusted data given by\n$$y_t - S_t = T_t + R_t$$\n  -  Multiplicative decomposition: seasonally adjusted data given by\n$$y_t / S_t = T_t \\times R_t$$\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  autoplot(Employed, color='gray') +\n  autolayer(components(dcmp), season_adjust, color='#0072B2') +\n  labs(y=\"Persons (thousands)\", title=\"Total employment in US retail\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/usretail-sa-1.png){width=960}\n:::\n:::\n\n\n\n\n## Seasonal adjustment\n\n  - We use estimates of $S$ based on past values to seasonally adjust a current value.\n  -  Seasonally adjusted series reflect **remainders** as well as **trend**. Therefore they are not \"smooth\" and \"downturns\" or \"upturns\" can be misleading.\n  -  It is better to use the trend-cycle component to look for turning points.\n\n# Moving Averages (MA)\n\n## Moving Averages {.smaller}\n\n- The classical method of time series decomposition originated in the 1920s and was widely used until the 1950s. \n- A moving average of order $m$ can be written as \n$$\\hat{T}_t = \\frac{1}{m}\\Sigma_{j=-k}^k y_{t+j}$$\nwhere $m = 2k+1$. \n- That is, the estimate of the trend-cycle at time $t$ is obtained by averaging values of the time series within $k$ periods of $t$.\n\n\n## MA\n\n- Averaging eliminates some of the randomness in the data, leaving a smooth trend-cycle component. \n- Called an m-MA, or MA(m), meaning a moving average of order m.\n\n## MA global economy\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Country == \"Australia\") |>\n  autoplot(Exports) +\n  labs(y = \"% of GDP\", title = \"Total Australian exports\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/globa_econ_MA-1.png){width=960}\n:::\n:::\n\n\n\n\n## MA global economy\n\n- A moving average is a an average that moves...\n- MA(5) would mean we use the average of two time series values before $y_t$, $y_t$ itself, and the two values after $y_t$.\n - Ex: to get the MA(5) for $y_{100}$ we would use the average of $y_{98},y_{99},y_{100},y_{101}$ and $y_{102}$. \n- What is a limitation of this method? \n\n## MA global economy sliding window\n\n- slide_dbl() from the slider package applies a function to “sliding” time windows. In this case, we use the mean() function with a window of size 5.\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_exports <- global_economy |>\n  filter(Country == \"Australia\") |>\n  mutate(\n    `5-MA` = slider::slide_dbl(Exports, mean,\n                .before = 2, .after = 2, .complete = TRUE)\n  )\n```\n:::\n\n\n\n\n## MA trend line\n\n:::{.panel-tabset}\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_exports |>\n  autoplot(Exports) +\n  geom_line(aes(y = `5-MA`), colour = \"#D55E00\") +\n  labs(y = \"% of GDP\",\n       title = \"Total Australian exports\") \n```\n:::\n\n\n\n\n### Plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n# History of time series decomposition\n\n## History of time series decomposition\n\n  -  Classical method originated in 1920s.\n  -  Census II method introduced in 1957. Basis for X-11 method and variants (including X-12-ARIMA, X-13-ARIMA)\n  -  STL method introduced in 1983\n  -  TRAMO/SEATS introduced in 1990s.\n\n\n\n## National Statistics Offices\n - ABS uses X-12-ARIMA\n - US Census Bureau uses X-13ARIMA-SEATS\n - Statistics Canada uses X-12-ARIMA\n - ONS (UK) uses X-12-ARIMA\n - EuroStat use X-13ARIMA-SEATS\n\n## X-11 decomposition {.smaller}\n\n**Advantages**\n\n  -  Relatively robust to outliers\n  -  Completely automated choices for trend and seasonal changes\n  -  Very widely tested on economic data over a long period of time.\n\n. . .\n\n**Disadvantages**\n\n  -  No prediction/confidence intervals\n  -  Ad hoc method with no underlying model\n  -  Only developed for quarterly and monthly data\n\n## Extensions: X-12-ARIMA and X-13-ARIMA {.smaller}\n\n  -  The X-11, X-12-ARIMA and X-13-ARIMA methods are based on Census II decomposition.\n  -  These allow adjustments for trading days and other explanatory variables.\n  -  Known outliers can be omitted.\n  -  Level shifts and ramp effects can be modelled.\n  -  Missing values estimated and replaced.\n  -  Holiday factors (e.g., Easter, Labour Day) can be estimated.\n\n## X-13ARIMA-SEATS {.smaller}\n\n**Advantages**\n\n  - Model-based\n  - Smooth trend estimate\n  - Allows estimates at end points\n  - Allows changing seasonality\n  - Developed for economic data\n\n. . .\n\n**Disadvantages**\n\n  -  Only developed for quarterly and monthly data\n\n# STL decomposition\n\n## STL decomposition {.smaller}\n\n  -  STL: \"Seasonal and Trend decomposition using Loess\"\n  -  Very versatile and robust.\n  -  Unlike X-12-ARIMA, STL will handle any type of seasonality.\n  -  Seasonal component allowed to change over time, and rate of change controlled by user.\n  -  Smoothness of trend-cycle also controlled by user.\n  -  Robust to outliers\n  -  Not trading day or calendar adjustments.\n  -  Only additive.\n  -  Take logs to get multiplicative decomposition.\n  -  Use Box-Cox transformations to get other decompositions.\n\n## STL decomposition\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  model(STL(Employed ~ season(window=9), robust=TRUE)) |>\n  components() |> autoplot() +\n    labs(title = \"STL decomposition: US retail employment\")\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/stlwindow9-1.png){width=816}\n:::\n:::\n\n\n\n\n## STL decomposition\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/stlwindowanim-1.gif)\n:::\n:::\n\n\n\n\n\n## STL decomposition {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  model(STL(Employed ~ season(window=5))) |>\n  components()\n\nus_retail_employment |>\n  model(STL(Employed ~ trend(window=15) +\n                       season(window=\"periodic\"),\n            robust = TRUE)\n  ) |> components()\n```\n:::\n\n\n\n\n\n  -  `trend(window = ?)` controls wiggliness of trend component.\n  -  `season(window = ?)` controls variation on seasonal component.\n  -  `season(window = 'periodic')` is equivalent to an infinite window.\n\n## STL decomposition {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  model(STL(Employed)) |>\n  components() |> autoplot()\n```\n\n::: {.cell-output-display}\n![](3-decomposition_files/figure-revealjs/mstl-1.png){width=816}\n:::\n:::\n\n\n\n\n:::{.callout-note}\n`STL()` chooses \\texttt{season(window=13)} by default. This can include transformations.\n:::\n\n## STL decomposition {.smaller}\n\n- Algorithm that updates trend and seasonal components iteratively.\n- Starts with $\\hat{T}_t=0$\n- Uses a mixture of loess and moving averages to successively refine the trend and seasonal estimates.\n- The trend window controls loess bandwidth applied to deasonalised values.\n- The season window controls loess bandwidth applied to detrended subseries.\n- Robustness weights based on remainder.\n- Default season `window = 13`\n- Default trend `window = nextodd(` \\newline\\mbox{}\\hfill `ceiling((1.5*period)/(1-(1.5/s.window)))`\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}