{
  "hash": "7c4a6c496800a282bcf97d25964cbc85",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 5\\nForecasters Toolbox\"\nformat: \n  revealjs:\n    output-file: \"5-toolbox.html\"\n  html:\n    output-file: \"5-toolbox_o.html\"\nlogo: \"../img/favicon.png\"\n---\n\n\n\n\n# A tidy forecasting workflow\n\n## Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpp3)\n```\n:::\n\n\n\n\n## A tidy forecasting workflow\n\nThe process of producing forecasts can be split up into a few fundamental steps.\n\n1. Preparing data\n2. Data visualization\n3. Specifying a model\n4. Model estimation\n5. Accuracy \\& performance evaluation\n6. Producing forecasts\n\n## A tidy forecasting workflow\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/workflow-1.png){width=960}\n:::\n:::\n\n\n\n\n## Data preparation (tidy)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngdppc <- global_economy |>\n  mutate(GDP_per_capita = GDP/Population) |>\n  select(Year, Country, GDP, Population, GDP_per_capita)\ngdppc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 15,150 x 5 [1Y]\n# Key:       Country [263]\n    Year Country             GDP Population GDP_per_capita\n   <dbl> <fct>             <dbl>      <dbl>          <dbl>\n 1  1960 Afghanistan  537777811.    8996351           59.8\n 2  1961 Afghanistan  548888896.    9166764           59.9\n 3  1962 Afghanistan  546666678.    9345868           58.5\n 4  1963 Afghanistan  751111191.    9533954           78.8\n 5  1964 Afghanistan  800000044.    9731361           82.2\n 6  1965 Afghanistan 1006666638.    9938414          101. \n 7  1966 Afghanistan 1399999967.   10152331          138. \n 8  1967 Afghanistan 1673333418.   10372630          161. \n 9  1968 Afghanistan 1373333367.   10604346          130. \n10  1969 Afghanistan 1408888922.   10854428          130. \n# ℹ 15,140 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Data visualisation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngdppc |>\n  filter(Country==\"Sweden\") |>\n  autoplot(GDP_per_capita) +\n    labs(title = \"GDP per capita for Sweden\", y = \"$US\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/GDP-plot-1.png){width=960}\n:::\n:::\n\n\n\n\n## Model estimation\n\nThe `model()` function trains models to data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- gdppc |>\n  model(trend_model = TSLM(GDP_per_capita ~ trend())) # TSLM to be covered later\nfit |> head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 5 x 2\n# Key:     Country [5]\n  Country        trend_model\n  <fct>              <model>\n1 Afghanistan         <TSLM>\n2 Albania             <TSLM>\n3 Algeria             <TSLM>\n4 American Samoa      <TSLM>\n5 Andorra             <TSLM>\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nA \\texttt{mable} is a model table, each cell corresponds to a fitted model.\n:::\n\n## Producing forecasts\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> forecast(h = \"3 years\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 789 x 5 [1Y]\n# Key:     Country, .model [263]\n   Country  .model  Year   GDP_per_capita\n   <fct>    <chr>  <dbl>           <dist>\n 1 Afghani… trend…  2018     N(526, 9653)\n 2 Afghani… trend…  2019     N(534, 9689)\n 3 Afghani… trend…  2020     N(542, 9727)\n 4 Albania  trend…  2018  N(4716, 476419)\n 5 Albania  trend…  2019  N(4867, 481086)\n 6 Albania  trend…  2020  N(5018, 486012)\n 7 Algeria  trend…  2018  N(4410, 643094)\n 8 Algeria  trend…  2019  N(4489, 645311)\n 9 Algeria  trend…  2020  N(4568, 647602)\n10 America… trend…  2018 N(12491, 652926)\n# ℹ 779 more rows\n# ℹ 1 more variable: .mean <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n:::{.callout-note}\nA \\texttt{fable} is a forecast table with point forecasts and distributions.\n:::\n\n## Visualising forecasts\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> forecast(h = \"3 years\") |>\n  filter(Country==\"Sweden\") |>\n  autoplot(gdppc) +\n    labs(title = \"GDP per capita for Sweden\", y = \"$US\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/GDP-fc-plot-1.png){width=960}\n:::\n:::\n\n\n\n\n# Some simple forecasting methods\n\n## `MEAN(y)`: Average method {.smaller}\n\n  * Forecast of all future values is equal to mean of historical data $\\{y_1,\\dots,y_T\\}$.\n  * Forecasts: $\\hat{y}_{T+h|T} = \\bar{y} = (y_1+\\dots+y_T)/T$\n\n. . .\n\n## `MEAN(y)`: Average method Plot\n\n:::{.panel-tabset}\n\n### Code \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbricks <- aus_production |>\n  filter(!is.na(Bricks)) |>\n  mutate(average = mean(Bricks))\n\nfc <- bricks |>\n  filter(row_number() == n()) |> as_tibble() |>\n  unnest(Quarter = list(as.Date(Quarter) + months(c(0, 12*5))))\n\nbricks |>\n  ggplot(aes(x = Quarter, y = Bricks)) +\n  geom_line() +\n  geom_line(aes(y = average), colour = \"#0072B2\", linetype = \"dashed\") +\n  geom_line(aes(y = average), data = fc, colour = \"#0072B2\") +\n  labs(title = \"Clay brick production in Australia\")\n```\n:::\n\n\n\n\n### Plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## `NAIVE(y)`: Naïve method {.smaller}\n\n  * Forecasts equal to last observed value.\n  * Forecasts: $\\hat{y}_{T+h|T} =y_T$.\n  * Consequence of efficient market hypothesis.\n\n. . .\n\n:::{.panel-tabset}\n\n### Code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbricks |>\n  filter(!is.na(Bricks)) |>\n  model(NAIVE(Bricks)) |>\n  forecast(h = \"5 years\") |>\n  autoplot(filter(bricks, year(Quarter) > 1990), level = NULL) +\n    geom_point(data = slice(bricks, n()), aes(y=Bricks), colour = \"#0072B2\") +\n    labs(title = \"Clay brick production in Australia\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/naive-method-explained-1.png){width=960}\n:::\n:::\n\n\n\n\n### Plot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## `SNAIVE(y ~ lag(m))`: Seasonal naïve method {.smaller}\n\n  * Forecasts equal to last value from same season.\n  * Forecasts: $\\hat{y}_{T+h|T} =y_{T+h-m(k+1)}$, where $m=$ seasonal period and $k$ is the integer part of $(h-1)/m$.\n\n\n. . .\n\n:::{.panel-tabset}\n\n### Code \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbricks |>\n  model(SNAIVE(Bricks ~ lag(\"year\"))) |>\n  forecast(h = \"5 years\") |>\n  autoplot(filter(bricks, year(Quarter) > 1990), level = NULL) +\n  geom_point(data = slice(bricks, (n()-3):n()), aes(y=Bricks), colour = \"#0072B2\") +\n  labs(title = \"Clay brick production in Australia\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/snaive-method-explained-1.png){width=960}\n:::\n:::\n\n\n\n\n### Plot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## `RW(y ~ drift())`: Drift method\n\n:::{.panel-tabset}\n\n### Definition\n\n * Forecasts equal to last value plus average change.\n * Forecasts:\\vspace*{-.7cm}\n\n \\begin{align*}\n \\hat{y}_{T+h|T} & =  y_{T} + \\frac{h}{T-1}\\sum_{t=2}^T (y_t-y_{t-1})\\\\\n                 & = y_T + \\frac{h}{T-1}(y_T -y_1).\n \\end{align*}\\vspace*{-0.2cm}\n\n   * Equivalent to extrapolating a line drawn between first and last observations.\n\n### Code & Plot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/drift-method-explained-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## Model fitting\n\nThe `model()` function trains models to data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrick_fit <-  aus_production |>\n  filter(!is.na(Bricks)) |>\n  model(\n    Seasonal_naive = SNAIVE(Bricks),\n    Naive = NAIVE(Bricks),\n    Drift = RW(Bricks ~ drift()),\n    Mean = MEAN(Bricks)\n  )\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 1 x 4\n  Seasonal_naive   Naive         Drift    Mean\n         <model> <model>       <model> <model>\n1       <SNAIVE> <NAIVE> <RW w/ drift>  <MEAN>\n```\n\n\n:::\n:::\n\n\n\n\n## Producing forecasts\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrick_fc <- brick_fit |>\n  forecast(h = \"5 years\")\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 80 x 4 [1Q]\n# Key:     .model [4]\n  .model   Quarter       Bricks .mean\n  <chr>      <qtr>       <dist> <dbl>\n1 Seasona… 2005 Q3 N(428, 2336)   428\n2 Seasona… 2005 Q4 N(397, 2336)   397\n3 Seasona… 2006 Q1 N(355, 2336)   355\n4 Seasona… 2006 Q2 N(435, 2336)   435\n# ℹ 76 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Visualising forecasts\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrick_fc |>\n  autoplot(aus_production, level = NULL) +\n  labs(title = \"Clay brick production in Australia\",\n       y = \"Millions of bricks\") +\n  guides(colour = guide_legend(title = \"Forecast\"))\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/brick-fc-plot-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n\n\n## Facebook closing stock price\n\n:::{.panel-tabset}\n\n### Code \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract training data\nfb_stock <- gafa_stock |>\n  filter(Symbol == \"FB\") |>\n  mutate(trading_day = row_number()) |>\n  update_tsibble(index=trading_day, regular=TRUE)\n\n# Specify, estimate and forecast\nfb_stock |>\n  model(\n    Mean = MEAN(Close),\n    Naive = NAIVE(Close),\n    Drift = RW(Close ~ drift())\n  ) |>\n  forecast(h=42) |>\n  autoplot(fb_stock, level = NULL) +\n  labs(title = \"Facebook closing stock price\", y=\"$US\") +\n  guides(colour=guide_legend(title=\"Forecast\"))\n```\n:::\n\n\n\n\n### Plot\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n\n\n## Your turn\n\n * Produce forecasts using an appropriate benchmark method for household wealth (`hh_budget`). Plot the results using `autoplot()`.\n * Produce forecasts using an appropriate benchmark method for Australian takeaway food turnover (`aus_retail`). Plot the results using `autoplot()`.\n\n# Residual diagnostics\n\n## Fitted values {.smaller}\n\n - $\\hat{y}_{t|t-1}$ is the forecast of $y_t$ based on observations $y_1,\\dots,y_{t-1}$.\n - We call these \"fitted values\".\n - Sometimes drop the subscript: $\\hat{y}_t \\equiv \\hat{y}_{t|t-1}$.\n - Often not true forecasts since parameters are estimated on all data.\n\n. . .\n\n*For example:*\n\n - $\\hat{y}_{t} = \\bar{y}$ for average method.\n - $\\hat{y}_{t} = y_{t-1} + (y_{T}-y_1)/(T-1)$ for drift method.\n\n## Forecasting residuals {.smaller}\n\n*Residuals in forecasting:* difference between observed value and its fitted value: $e_t = y_t-\\hat{y}_{t|t-1}$.\n\n. . .\n\n\n**Assumptions**\n\n  1. $\\{e_t\\}$ uncorrelated. If they aren't, then information left in  residuals that should be used in computing forecasts.\n  2. $\\{e_t\\}$ have mean zero. If they don't, then forecasts are biased.\n\n. . .\n\n**Useful properties** (for distributions & prediction intervals)\n\n  3. $\\{e_t\\}$ have constant variance.\n  4. $\\{e_t\\}$ are normally distributed.\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfb_stock |> autoplot(Close)\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/fbf-1.png){width=960}\n:::\n:::\n\n\n\n\n## Facebook closing stock price {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- fb_stock |> model(NAIVE(Close))\naugment(fit) |> head(5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 5 x 7 [1]\n# Key:       Symbol, .model [1]\n  Symbol .model       trading_day Close .fitted .resid .innov\n  <chr>  <chr>              <int> <dbl>   <dbl>  <dbl>  <dbl>\n1 FB     NAIVE(Close)           1  54.7    NA   NA     NA    \n2 FB     NAIVE(Close)           2  54.6    54.7 -0.150 -0.150\n3 FB     NAIVE(Close)           3  57.2    54.6  2.64   2.64 \n4 FB     NAIVE(Close)           4  57.9    57.2  0.720  0.720\n5 FB     NAIVE(Close)           5  58.2    57.9  0.310  0.310\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\nNaive forecasts:\n\n$\\hat{y}_{t|t-1} = y_{t-1}$\n\n$e_t  = y_t - \\hat{y}_{t|t-1} = y_t-y_{t-1}$\n\nWhere .fitted = $\\hat{y}_{t|t-1}$ and .resid = $\\phantom{\\hat{y}_{|}}{e}_{t}\\phantom{\\hat{y}_{|}}$\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  ggplot(aes(x = trading_day)) +\n  geom_line(aes(y = Close, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\"))\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  filter(trading_day > 1100) |>\n  ggplot(aes(x = trading_day)) +\n  geom_line(aes(y = Close, colour = \"Data\")) +\n  geom_line(aes(y = .fitted, colour = \"Fitted\"))\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj4a-1.png){width=960}\n:::\n:::\n\n\n\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  autoplot(.resid) +\n  labs(y = \"$US\",\n       title = \"Residuals from naïve method\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj5-1.png){width=960}\n:::\n:::\n\n\n\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  ggplot(aes(x = .resid)) +\n  geom_histogram(bins = 150) +\n  labs(title = \"Histogram of residuals\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj6-1.png){width=960}\n:::\n:::\n\n\n\n\n## Facebook closing stock price\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  ACF(.resid) |>\n  autoplot() + labs(title = \"ACF of residuals\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj7-1.png){width=960}\n:::\n:::\n\n\n\n\n## `gg_tsresiduals()` function\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/dj10-1.png){width=960}\n:::\n:::\n\n\n\n\n## ACF of residuals\n\n  * We assume that the residuals are white noise (uncorrelated, mean zero, constant variance). If they aren't, then there is information left in  the residuals that should be used in computing forecasts.\n\n  * So a standard residual diagnostic is to check the ACF of the residuals of a forecasting method.\n\n  * We *expect* these to look like white noise.\n\n## Portmanteau tests: Box-Pierce test {.smaller}\n\n$r_k = $ autocorrelation of residual at lag $k$\n\n. . .\n\nConsider a *whole set* of $r_{k}$ values, and develop a test to see whether the set is significantly different from a zero set.\n\n**Box-Pierce test**\n$$Q = T \\sum_{k=1}^\\ell r_k^2$$\nwhere $\\ell$  is max lag being considered and $T$ is number of observations.\n\n  * If each $r_k$ close to zero, $Q$ will be **small**.\n  * If some $r_k$ values large (positive or negative), $Q$ will be **large**.\n\n\n\n## Portmanteau tests: Ljung-Box test (more accurate) (1/2) {.smaller}\n\n$r_k = $ autocorrelation of residual at lag $k$\n\n. . .\n\nConsider a *whole set* of $r_{k}$  values, and develop a test to see whether the set is significantly different from a zero set.\n\n**Ljung-Box test**\n $$Q^* = T(T+2) \\sum_{k=1}^\\ell (T-k)^{-1}r_k^2$$$\nwhere $\\ell$  is max lag being considered and $T$ is number of observations.\n\n## Portmanteau tests: Ljung-Box test (more accurate) (2/2) {.smaller}\n\n  * If each $r_k$ close to zero, $Q^*$ will be **small**.\n  * If some $r_k$ values large (positive or negative), $Q$ will be **large**.\n  * Use $\\ell=10$ for non-seasonal data, $\\ell=2m$ for seasonal data (where $m$ is seasonal period).\n  * Better performance, especially in small samples. Test is not good when $\\ell$ is large, so if these values are larger than $T/5$, then use $\\ell=T/5$\n  * How large is too large? \n\n## Portmanteau tests {.smaller}\n\n  * If data are WN, $Q$ and $Q^*$ have $\\chi^2$ distribution with  $\\ell$ degrees of freedom.\n\n  * `lag` $= \\ell$\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.resid, box_pierce, lag=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  Symbol .model       bp_stat bp_pvalue\n  <chr>  <chr>          <dbl>     <dbl>\n1 FB     NAIVE(Close)    12.1     0.281\n```\n\n\n:::\n:::\n\n\n\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.resid, ljung_box, lag=10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  Symbol .model       lb_stat lb_pvalue\n  <chr>  <chr>          <dbl>     <dbl>\n1 FB     NAIVE(Close)    12.1     0.276\n```\n\n\n:::\n:::\n\n\n\n\n# Distributional forecasts and prediction intervals\n\n## Forecast distributions\n\n * A forecast $\\hat{y}_{T+h|T}$ is (usually) the mean of the conditional distribution $y_{T+h} \\mid y_1, \\dots, y_{T}$.\n * Most time series models produce normally distributed forecasts.\n * The forecast distribution describes the probability of observing any future value.\n\n## Forecast distributions {.smaller}\n\nAssuming residuals are normal, uncorrelated, sd = $\\hat\\sigma$:\n\n. . .\n\n| Method          \t| Forecast Distribution                                                            \t|\n|-----------------\t|----------------------------------------------------------------------------------\t|\n| Mean:           \t| $y_{T+h\\|T} \\sim N(\\bar{y}, (1 + 1/T)\\hat{\\sigma}^2)$                            \t|\n| Naïve:          \t| $y_{T+h\\|T} \\sim N(y_T, h\\hat{\\sigma}^2)$                                        \t|\n| Seasonal naïve: \t| $y_{T+h\\|T} \\sim N(y_{T+h-m(k+1)}, (k+1)\\hat{\\sigma}^2)$                         \t|\n| Drift:          \t| $y_{T+h\\|T} \\sim N(y_T + \\frac{h}{T-1}(y_T - y_1),h\\frac{T+h}{T}\\hat{\\sigma}^2)$ \t|\n\nwhere $k$ is the integer part of $(h-1)/m$.\n\n:::{.callout-note}\nWhen $h=1$ and $T$ is large, these all give the same approximate forecast variance: $\\hat{\\sigma}^2$.\n:::\n\n## Prediction intervals {.smaller}\n\n * A prediction interval gives a region within which we expect $y_{T+h}$ to lie with a specified probability.\n * Assuming forecast errors are normally distributed, then a 95% PI is\n\n. . .\n\n  $$\\hat{y}_{T+h|T} \\pm 1.96 \\hat\\sigma_h$$\n\nwhere $\\hat\\sigma_h$ is the st dev of the $h$-step distribution.\n\n:::{.callout-note}\nWhen $h=1$, $\\hat\\sigma_h$ can be estimated from the residuals.\n:::\n\n## Prediction intervals\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrick_fc |> hilo(level = 95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 80 x 5 [1Q]\n# Key:       .model [4]\n   .model  Quarter       Bricks .mean\n   <chr>     <qtr>       <dist> <dbl>\n 1 Season… 2005 Q3 N(428, 2336)   428\n 2 Season… 2005 Q4 N(397, 2336)   397\n 3 Season… 2006 Q1 N(355, 2336)   355\n 4 Season… 2006 Q2 N(435, 2336)   435\n 5 Season… 2006 Q3 N(428, 4672)   428\n 6 Season… 2006 Q4 N(397, 4672)   397\n 7 Season… 2007 Q1 N(355, 4672)   355\n 8 Season… 2007 Q2 N(435, 4672)   435\n 9 Season… 2007 Q3 N(428, 7008)   428\n10 Season… 2007 Q4 N(397, 7008)   397\n# ℹ 70 more rows\n# ℹ 1 more variable: `95%` <hilo>\n```\n\n\n:::\n:::\n\n\n\n\n## Prediction intervals {.smaller}\n\n * Point forecasts often useless without a measure of uncertainty (such as prediction intervals).\n * Prediction intervals require a stochastic model (with random errors, etc).\n * For most models, prediction intervals get wider as the forecast horizon increases.\n * Use `level` argument to control coverage.\n * Check residual assumptions before believing them.\n * Usually too narrow due to unaccounted uncertainty.\n\n# Forecasting with transformations\n\n## Modelling with transformations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neggs <- prices |>\n  filter(!is.na(eggs)) |> select(eggs)\neggs |> autoplot() +\n  labs(title=\"Annual egg prices\",\n       y=\"$US (adjusted for inflation)\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/food-1.png){width=960}\n:::\n:::\n\n\n\n\n## Modelling with transformations {.smaller}\n\nTransformations used in the left of the formula will be automatically back-transformed. To model log-transformed egg prices, you could use:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- eggs |>\n  model(RW(log(eggs) ~ drift()))\nfit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 1 x 1\n  `RW(log(eggs) ~ drift())`\n                    <model>\n1             <RW w/ drift>\n```\n\n\n:::\n:::\n\n\n\n\n## Forecasting with transformations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc <- fit |>\n  forecast(h = 50)\nfc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 50 x 4 [1Y]\n# Key:     .model [1]\n   .model                   year             eggs .mean\n   <chr>                   <dbl>           <dist> <dbl>\n 1 RW(log(eggs) ~ drift())  1994 t(N(4.1, 0.018))  61.8\n 2 RW(log(eggs) ~ drift())  1995 t(N(4.1, 0.036))  61.4\n 3 RW(log(eggs) ~ drift())  1996 t(N(4.1, 0.055))  61.0\n 4 RW(log(eggs) ~ drift())  1997 t(N(4.1, 0.074))  60.6\n 5 RW(log(eggs) ~ drift())  1998 t(N(4.1, 0.093))  60.2\n 6 RW(log(eggs) ~ drift())  1999    t(N(4, 0.11))  59.8\n 7 RW(log(eggs) ~ drift())  2000    t(N(4, 0.13))  59.4\n 8 RW(log(eggs) ~ drift())  2001    t(N(4, 0.15))  59.0\n 9 RW(log(eggs) ~ drift())  2002    t(N(4, 0.18))  58.6\n10 RW(log(eggs) ~ drift())  2003     t(N(4, 0.2))  58.3\n# ℹ 40 more rows\n```\n\n\n:::\n:::\n\n\n\n\n## Forecasting with transformations\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc |> autoplot(eggs) +\n  labs(title=\"Annual egg prices\",\n       y=\"US$ (adjusted for inflation)\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/elec9-1.png){width=960}\n:::\n:::\n\n\n\n\n## Bias adjustment {.smaller}\n\n  * Back-transformed point forecasts are medians.\n  * Back-transformed PI have the correct coverage.\n\n. . .\n\n**Back-transformed means (if you are math inclined)**\n\nLet $X$ be have mean $\\mu$ and variance $\\sigma^2$.\n\nLet $f(x)$ be back-transformation function, and $Y=f(X)$.\n\nTaylor series expansion about $\\mu$:\n$$f(X) = f(\\mu) + (X-\\mu)f'(\\mu) + \\frac{1}{2}(X-\\mu)^2f''(\\mu).$$\n\n:::{.callout-note}\n\\centerline{$\\E[Y] = \\E[f(X)] = f(\\mu) + \\frac12 \\sigma^2 f''(\\mu)$}\n:::\n\n## Bias adjustment {.smaller}\n\n\n\n**Box-Cox back-transformation (if math inclined):**\n\\begin{align*}\ny_t &= \\left\\{\\begin{array}{ll}\n        \\exp(w_t)      & \\quad \\lambda = 0; \\\\\n        (\\lambda W_t+1)^{1/\\lambda}  & \\quad \\lambda \\ne 0.\n\\end{array}\\right. \\\\\nf(x) &= \\begin{cases}\n                        e^x & \\quad\\lambda=0;\\\\\n (\\lambda x + 1)^{1/\\lambda} & \\quad\\lambda\\ne0.\n \\end{cases}\\\\\nf''(x) &= \\begin{cases}\n                        e^x & \\quad\\lambda=0;\\\\\n (1-\\lambda)(\\lambda x + 1)^{1/\\lambda-2} & \\quad\\lambda\\ne0.\n \\end{cases}\n\\end{align*}\n\n:::{.callout-note}\n\\centerline{$\\E[Y] = \\begin{cases}\n                        e^\\mu\\left[1+\\frac{\\sigma^2}{2}\\right] & \\quad\\lambda=0;\\\\\n (\\lambda \\mu + 1)^{1/\\lambda}\\left[1+\\frac{\\sigma^2(1-\\lambda)}{2(\\lambda\\mu+1)^2}\\right] & \\quad\\lambda\\ne0.\n \\end{cases}$}\n:::\n\n## Bias adjustment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc |>\n  autoplot(eggs, level = 80, point_forecast = lst(mean, median)) +\n  labs(title=\"Annual egg prices\",\n       y=\"US$ (adjusted for inflation)\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/biasadj-1.png){width=960}\n:::\n:::\n\n\n\n\n# Forecasting and decomposition\n\n## Forecasting and decomposition\n\n$$y_t = \\hat{S}_t + \\hat{A}_t$$\n\n- $\\hat{A}_t$ is seasonally adjusted component\n- $\\hat{S}_t$ is seasonal component.\n\n\n  *  Forecast $\\hat{S}_t$ using SNAIVE.\n  *  Forecast $\\hat{A}_t$ using non-seasonal time series method.\n  *  Combine forecasts of $\\hat{S}_t$ and $\\hat{A}_t$ to get forecasts of original data.\n\n## US Retail Employment\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment <- us_employment |>\n  filter(year(Month) >= 1990, Title == \"Retail Trade\") |>\n  select(-Series_ID)\nus_retail_employment\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 357 x 3 [1M]\n      Month Title        Employed\n      <mth> <chr>           <dbl>\n 1 1990 Jan Retail Trade   13256.\n 2 1990 Feb Retail Trade   12966.\n 3 1990 Mar Retail Trade   12938.\n 4 1990 Apr Retail Trade   13012.\n 5 1990 May Retail Trade   13108.\n 6 1990 Jun Retail Trade   13183.\n 7 1990 Jul Retail Trade   13170.\n 8 1990 Aug Retail Trade   13160.\n 9 1990 Sep Retail Trade   13113.\n10 1990 Oct Retail Trade   13185.\n# ℹ 347 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcmp <- us_retail_employment |>\n  model(STL(Employed)) |>\n  components() |> select(-.model)\ndcmp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tsibble: 357 x 6 [1M]\n      Month Employed  trend season_year remainder season_adjust\n      <mth>    <dbl>  <dbl>       <dbl>     <dbl>         <dbl>\n 1 1990 Jan   13256. 13288.      -33.0      0.836        13289.\n 2 1990 Feb   12966. 13269.     -258.     -44.6          13224.\n 3 1990 Mar   12938. 13250.     -290.     -22.1          13228.\n 4 1990 Apr   13012. 13231.     -220.       1.05         13232.\n 5 1990 May   13108. 13211.     -114.      11.3          13223.\n 6 1990 Jun   13183. 13192.      -24.3     15.5          13207.\n 7 1990 Jul   13170. 13172.      -23.2     21.6          13193.\n 8 1990 Aug   13160. 13151.       -9.52    17.8          13169.\n 9 1990 Sep   13113. 13131.      -39.5     22.0          13153.\n10 1990 Oct   13185. 13110.       61.6     13.2          13124.\n# ℹ 347 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcmp_forecast<- dcmp |>\n                model(NAIVE(season_adjust)) |>\n                forecast()\n\n  autoplot(dcmp_forecast,dcmp) +\n  labs(title = \"Naive forecasts of seasonally adjusted data\")\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/usretail2-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n## US Retail Employment\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nus_retail_employment |>\n  model(stlf = decomposition_model(\n    STL(Employed ~ trend(window = 7), robust = TRUE),\n    NAIVE(season_adjust)\n  )) |>\n  forecast() |>\n  autoplot(us_retail_employment)\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/usretail3-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n## Decomposition models {.smaller}\n\n`decomposition_model()` creates a decomposition model\n\n * You must provide a method for forecasting the `season_adjust` series.\n * A seasonal naive method is used by default for the `seasonal` components.\n * The variances from both the seasonally adjusted and seasonal forecasts are combined.\n\n# Evaluating forecast accuracy\n\n## Training and test sets (1/2)\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/traintest-1.png){width=960}\n:::\n:::\n\n\n\n\n\n## Training and test sets (2/2)\n\n-   A model which fits the training data well will not necessarily forecast well.\n-   A perfect fit can always be obtained by using a model with enough parameters.\n-   Over-fitting a model to data is just as bad as failing to identify a systematic pattern in the data.\n  * **The test set must not be used for *any* aspect of model development or calculation of forecasts.**\n  * Forecast accuracy is based only on the test set.\n\n## Forecast errors\n\nForecast \"error\": the difference between an observed value and its forecast.\n$$\n  e_{T+h} = y_{T+h} - \\hat{y}_{T+h|T},\n$$\nwhere the training data is given by $\\{y_1,\\dots,y_T\\}$\n\n- Unlike residuals, forecast errors on the test set involve multi-step forecasts.\n- These are *true* forecast errors as the test data is not used in computing $\\hat{y}_{T+h|T}$.\n\n## Measures of forecast accuracy\n\n:::{.panel-tabset}\n\n### Code \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrain <- aus_production |>\n  filter(between(year(Quarter), 1992, 2007))\nbeer <- aus_production |>\n  filter(year(Quarter) >= 1992)\nbeer_fc_plot <- train |>\n  model(\n    Mean = MEAN(Beer),\n    Naive = NAIVE(Beer),\n    Seasonal_naive = SNAIVE(Beer),\n    Drift = RW(Beer ~ drift())\n  ) |>\n  forecast(h=11) |>\n  autoplot(beer, level = NULL) +\n    labs(title = \"Forecasts for quarterly beer production\",\n         y = \"Megalitres\") +\n    guides(colour=guide_legend(title=\"Forecast\"))\nbeer_fc_plot\n```\n:::\n\n\n\n\n### Plot\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n\n:::\n\n## Measures of forecast accuracy {.smaller}\n\n$y_{T+h}=  (T+h)$th observation, $h=1,\\dots,H$\n\n$\\hat{y}_{T+h|T}=$ its forecast based on data up to time $T$.\n\n$e_{T+h} = y_{T+h} - \\hat{y}_{{T+h}|{T}}$\n\n. . .\n\n| Name                        \t| Abb. \t| Formula                                    \t|\n|-----------------------------\t|------\t|--------------------------------------------\t|\n| Mean Abosolue Error         \t| MAE  \t| $\\text{mean}(\\|e_{T+h}\\|)$                 \t|\n| Mean Squared Error          \t| MSE  \t| $\\text{mean}(e_{T+h}^2)$                   \t|\n| Root MSE                    \t| RMSE \t| $\\sqrt{\\text{mean}(e_{T+h}^2)$             \t|\n| Mean Absolute Percent Error \t| MAPE \t| $100\\text{mean}(\\|e_{T+h}\\|/ \\|y_{T+h}\\|)$ \t|\n\n  * MAE, MSE, RMSE are all scale dependent.\n  * MAPE is scale independent but is only sensible if $y_t\\gg 0$ for all $t$, and $y$ has a natural zero.\n\n## Mean Absolute Scaled Error (non-seasonal) {.smaller}\n\n$$\n\\text{MASE} = \\text{mean}(|e_{T+h}|/Q)\n$$\n\nwhere $Q$ is a stable measure of the scale of the time series $\\{y_t\\}$.\n\nProposed by Hyndman and Koehler (IJF, 2006).\n\nFor non-seasonal time series,\n\n$$\n  Q = (T-1)^{-1}\\sum_{t=2}^T |y_t-y_{t-1}|\n$$\nworks well. Then MASE is equivalent to MAE relative to a naïve method.\n\n\n## Mean Absolute Scaled Error (seasonal){.smaller}\n\n$$\n\\text{MASE} = \\text{mean}(|e_{T+h}|/Q)\n$$\n\nwhere $Q$ is a stable measure of the scale of the time series $\\{y_t\\}$.\n\nProposed by Hyndman and Koehler (IJF, 2006).\n\nFor seasonal time series,\n$$\n  Q = (T-m)^{-1}\\sum_{t=m+1}^T |y_t-y_{t-m}|\n$$\nworks well. Then MASE is equivalent to MAE relative to a seasonal naïve method.\n\n\n## Measures of forecast accuracy: Time Series\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbeer_fc_plot\n```\n\n::: {.cell-output-display}\n![](5-toolbox_files/figure-revealjs/beer-fc-2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Measures of forecast accuracy: Model Fits\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecent_production <- aus_production |>\n  filter(year(Quarter) >= 1992)\ntrain <- recent_production |>\n  filter(year(Quarter) <= 2007)\nbeer_fit <- train |>\n  model(\n    Mean = MEAN(Beer),\n    Naive = NAIVE(Beer),\n    Seasonal_naive = SNAIVE(Beer),\n    Drift = RW(Beer ~ drift())\n  )\nbeer_fc <- beer_fit |>\n  forecast(h = 10)\n```\n:::\n\n\n\n\n## Measures of forecast accuracy: On Training data (1/2)\n\n* Smaller is better\n* Use to evaluate models individually (based on training data, overfitting possible)\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(beer_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 10\n  .model         .type           ME  RMSE   MAE    MPE  MAPE  MASE RMSSE   ACF1\n  <chr>          <chr>        <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl>\n1 Mean           Training  0         43.6  35.2 -0.937  7.89  2.46  2.60 -0.109\n2 Naive          Training  4.76e- 1  65.3  54.7 -0.916 12.2   3.83  3.89 -0.241\n3 Seasonal_naive Training -2.13e+ 0  16.8  14.3 -0.554  3.31  1     1    -0.288\n4 Drift          Training -5.41e-15  65.3  54.8 -1.03  12.2   3.83  3.89 -0.241\n```\n\n\n:::\n:::\n\n\n\n\n\n## Measures of forecast accuracy: On Training data (2/2)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(beer_fit) |>\n  arrange(.model) |> # Sorts model names alphabetically\n  select(.model, .type, RMSE, MAE, MAPE, MASE) #The metrics we defined\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  .model         .type     RMSE   MAE  MAPE  MASE\n  <chr>          <chr>    <dbl> <dbl> <dbl> <dbl>\n1 Drift          Training  65.3  54.8 12.2   3.83\n2 Mean           Training  43.6  35.2  7.89  2.46\n3 Naive          Training  65.3  54.7 12.2   3.83\n4 Seasonal_naive Training  16.8  14.3  3.31  1   \n```\n\n\n:::\n:::\n\n\n\n\n\n## Measures of forecast accuracy: On Testing data\n\n* Smaller is better\n* Can be used to compare models and evaluate models individually\n* Gives a realistic expectation of error if we rebuild model on all data for future forecasts\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(beer_fc, recent_production) |>\n  arrange(.model) |>\n  select(.model, .type, RMSE, MAE, MAPE, MASE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  .model         .type  RMSE   MAE  MAPE  MASE\n  <chr>          <chr> <dbl> <dbl> <dbl> <dbl>\n1 Drift          Test   64.9  58.9 14.6  4.12 \n2 Mean           Test   38.4  34.8  8.28 2.44 \n3 Naive          Test   62.7  57.4 14.2  4.01 \n4 Seasonal_naive Test   14.3  13.4  3.17 0.937\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}