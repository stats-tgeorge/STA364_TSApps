{
  "hash": "ae9b61f058c08101f24e78966d5b9615",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 9\\nARIMA\"\nformat: \n  revealjs:\n    output-file: \"9-arima.html\"\n  html:\n    output-file: \"9-arima_o.html\"\nlogo: \"../img/favicon.png\"\n---\n\n\n\n\n\n## Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\nlibrary(purrr)\nlibrary(fpp3) # Primary\n```\n:::\n\n\n\n\n## ARIMA models {.smaller}\n\n| **Component** | **Description**                                      |\n|---------------|------------------------------------------------------|\n| **AR**        | autoregressive (lagged observations as inputs)       |\n| **I**         | integrated (differencing to make series stationary)  |\n| **MA**        | moving average (lagged errors as inputs)             |\n\n. . .\n\n\n**An ARIMA model is rarely interpretable in terms of visible data structures like trend and seasonality. But it can capture a huge range of time series patterns.**\n\n# Stationarity and differencing\n\n## Stationarity\n\n**Definition**\nIf $\\{y_t\\}$ is a stationary time series, then for all $s$, the distribution of $(y_t,\\dots,y_{t+s})$ does not depend on $t$.\n\n\n. . .\n\nA **stationary series** is:\n\n* roughly horizontal\n* constant variance\n* no patterns predictable in the long-term\n\n## Stationary? (1/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngafa_stock |>\n  filter(Symbol == \"GOOG\", year(Date) == 2018) |>\n  autoplot(Close) +\n  labs(y = \"Google closing stock price\", x = \"Day\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (2/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngafa_stock |>\n  filter(Symbol == \"GOOG\", year(Date) == 2018) |>\n  autoplot(difference(Close)) +\n  labs(y = \"Google closing stock price\", x = \"Day\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (3/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Country == \"Algeria\") |>\n  autoplot(Exports) +\n  labs(y = \"% of GDP\", title = \"Algerian Exports\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (4/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_production |>\n  autoplot(Bricks) +\n  labs(title = \"Clay brick production in Australia\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (5/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprices |>\n  filter(year >= 1900) |>\n  autoplot(eggs) +\n  labs(y=\"$US (1993)\", title=\"Price of a dozen eggs\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (6/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_livestock |>\n  filter(Animal == \"Pigs\", State == \"Victoria\") |>\n  autoplot(Count/1e3) +\n  labs(y = \"thousands\", title = \"Total pigs slaughtered in Victoria\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (7/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_livestock |>\n  filter(Animal == \"Pigs\", State == \"Victoria\", year(Month) >= 2010) |>\n  autoplot(Count/1e3) +\n  labs(y = \"thousands\", title = \"Total pigs slaughtered in Victoria\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (8/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_livestock |>\n  filter(Animal == \"Pigs\", State == \"Victoria\", year(Month) >= 2015) |>\n  autoplot(Count/1e3) +\n  labs(y = \"thousands\", title = \"Total pigs slaughtered in Victoria\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationary? (9/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npelt |>\n  autoplot(Lynx) +\n  labs(y = \"Number trapped\", title = \"Annual Canadian Lynx Trappings\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationarity\n\n**Definition**\n\nIf $\\{y_t\\}$ is a stationary time series, then for all $s$, the distribution of $(y_t,\\dots,y_{t+s})$ does not depend on $t$.\n\n\n- Transformations help to **stabilize the variance**.\n\n- For ARIMA modelling, we also need to **stabilize the mean**.\n\n## Non-stationarity in the mean\n\n**Identifying non-stationary series**\n\n* time plot.\n* The ACF of stationary data drops to zero relatively quickly\n* The ACF of non-stationary data decreases slowly.\n* For non-stationary data, the value of $r_1$ is often large and positive.\n\n## Example: Google stock price (1/5)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 <- gafa_stock |>\n  filter(Symbol == \"GOOG\", year(Date) == 2018)\n```\n:::\n\n\n\n\n## Example: Google stock price (2/5)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |>\n  autoplot(Close) +\n  labs(y = \"Closing stock price ($USD)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Google stock price (3/5)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |> ACF(Close) |> autoplot()\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Google stock price (4/5)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |>\n  autoplot(difference(Close)) +\n  labs(y = \"Change in Google closing stock price ($USD)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Google stock price (5/5)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |> ACF(difference(Close)) |> autoplot()\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n\n## Differencing\n\n* Differencing helps to **stabilize the mean**.\n* The differenced series is the *change* between each observation in the original series: $y'_t = y_t - y_{t-1}$.\n* The differenced series will have only $T-1$ values since it is not possible to calculate a difference $y_1'$ for the first observation.\n\n## Random walk model {.smaller}\nIf differenced series is white noise with zero mean:\n\n\n$y_t-y_{t-1}=\\epsilon_t$ or $y_t=y_{t-1}+\\epsilon_t$\n\nwhere $\\epsilon_t \\sim NID(0,\\sigma^2)$.\n\n* Very widely used for non-stationary data.\n* This is the model behind the **naÃ¯ve method**.\n* Random walks typically have:\n    * long periods of apparent trends up or down\n    * Sudden/unpredictable changes in direction\n* Forecast are equal to the last observation\n    * future movements up or down are equally likely.\n\n## Random walk with drift model {.smaller}\n\nIf differenced series is white noise with non-zero mean:\n\n$y_t-y_{t-1}=c+\\epsilon_t$ \\hspace{0.4cm} or \\hspace{0.4cm} $y_t=c+y_{t-1}+\\epsilon_t$}\n\nwhere $\\epsilon_t \\sim NID(0,\\sigma^2)$.\n\n* $c$ is the **average change** between consecutive observations.\n* If $c>0$, $y_t$ will tend to drift upwards and vice versa.\n* This is the model behind the **drift method**.\n\n## Second-order differencing\n\nOccasionally the differenced data will not appear stationary and it may be necessary to difference the data a second time:\n\n. . .\n\n$$\n\\begin{align*}\ny''_{t} & = y'_{t} - y'_{t - 1} \\\\\n        & = (y_t - y_{t-1}) - (y_{t-1}-y_{t-2})\\\\\n        & = y_t - 2y_{t-1} +y_{t-2}.\n\\end{align*}\n$$\n\n* $y_t''$ will have $T-2$ values.\n* In practice, it is almost never necessary to go beyond second-order differences.\n\n## Seasonal differencing\n\nA seasonal difference is the difference between an observation and the corresponding observation from the previous year.\n\n$$\n y'_t = y_t - y_{t-m}\n$$\n\nwhere $m=$ number of seasons.\n\n* For monthly data $m=12$.\n* For quarterly data $m=4$.\n\n## Antidiabetic drug sales (1/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na10 <- PBS |>\n  filter(ATC2 == \"A10\") |>\n  summarise(Cost = sum(Cost)/1e6)\n```\n:::\n\n\n\n\n## Antidiabetic drug sales (2/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na10 |> autoplot(\n  Cost\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n\n\n## Antidiabetic drug sales (3/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na10 |> autoplot(\n  log(Cost)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n\n## Antidiabetic drug sales (4/4)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\na10 |> autoplot(\n  log(Cost) |> difference(12)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (1/6)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 <- PBS |>\n  filter(ATC2 == \"H02\") |>\n  summarise(Cost = sum(Cost)/1e6)\n```\n:::\n\n\n\n\n## Cortecosteroid drug sales (2/6)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  Cost\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (3/6)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  log(Cost)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (4/6)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  log(Cost) |> difference(12)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (5/6)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  log(Cost) |> difference(12) |> difference(1)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-23-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (6/6){.smaller}\n\n* Seasonally differenced series is closer to being stationary.\n* Remaining non-stationarity can be removed with further first difference.\n\n. . .\n\nIf $y'_t = y_t - y_{t-12}$ denotes seasonally differenced series, then twice-differenced series is\n\n\n\\begin{align*}\ny^*_t &= y'_t - y'_{t-1} \\\\\n      &= (y_t - y_{t-12}) - (y_{t-1} - y_{t-13}) \\\\\n      &= y_t - y_{t-1} - y_{t-12} + y_{t-13}\\: .\n\\end{align*}\n\n\n## Seasonal differencing\n\nWhen both seasonal and first differences are applied\\dots\n\n* it makes no difference which is done first---the result will be the same.\n* If seasonality is strong, we recommend that seasonal differencing be done first because sometimes the resulting series will be stationary and there will be no need for further first difference.\n\n. . .\n\nIt is important that if differencing is used, the differences are interpretable.\n\n## Interpretation of differencing\n\n* first differences are the change between **one observation and the next**;\n* seasonal differences are the change between **one year to the next**.\n\n. . .\n\nBut taking lag 3 differences for yearly data, for example, results in a model which cannot be sensibly interpreted.\n\n## Unit root tests\n\n**Statistical tests to determine the required order of differencing.**\n\n  1. Augmented Dickey Fuller test: null hypothesis is that the data are non-stationary and non-seasonal.\n  2. Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test: null hypothesis is that the data are stationary and non-seasonal.\n  3. Other tests available for seasonal data.\n\nWe will use the KPSS test. \n\n## KPSS test\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |>\n  features(Close, unitroot_kpss)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  Symbol kpss_stat kpss_pvalue\n  <chr>      <dbl>       <dbl>\n1 GOOG       0.573      0.0252\n```\n\n\n:::\n:::\n\n\n\n\n\\pause\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngoogle_2018 |>\n  features(Close, unitroot_ndiffs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 2\n  Symbol ndiffs\n  <chr>   <int>\n1 GOOG        1\n```\n\n\n:::\n:::\n\n\n\n\n## Automatically selecting differences (1/3)\n\nSTL decomposition: $y_t = T_t+S_t+R_t$\n\nSeasonal strength $F_s = \\max\\big(0, 1-\\frac{\\text{Var}(R_t)}{\\text{Var}(S_t+R_t)}\\big)$\n\nIf $F_s > 0.64$, do one seasonal difference.\n\n## Automatically selecting differences (2/3)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> mutate(log_sales = log(Cost)) |>\n  features(log_sales, list(unitroot_nsdiffs, feat_stl))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 10\n  nsdiffs trend_strength seasonal_strength_year seasonal_peak_year seasonal_trough_year\n    <int>          <dbl>                  <dbl>              <dbl>                <dbl>\n1       1          0.957                  0.955                  6                    8\n# â¹ 5 more variables: spikiness <dbl>, linearity <dbl>, curvature <dbl>,\n#   stl_e_acf1 <dbl>, stl_e_acf10 <dbl>\n```\n\n\n:::\n:::\n\n\n\n\n## Automatically selecting differences (3/3)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> mutate(log_sales = log(Cost)) |>\n  features(log_sales, unitroot_nsdiffs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 1\n  nsdiffs\n    <int>\n1       1\n```\n\n\n:::\n\n```{.r .cell-code}\nh02 |> mutate(d_log_sales = difference(log(Cost), 12)) |>\n  features(d_log_sales, unitroot_ndiffs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 1\n  ndiffs\n   <int>\n1      1\n```\n\n\n:::\n:::\n\n\n\n\n## Your turn\n\nFor the `tourism` dataset, compute the total number of trips and find an appropriate differencing (after transformation if necessary) to obtain stationary data.\n\n\n## Backshift notation (1/4) {.smaller}\n\nA very useful notational device is the backward shift operator, $B$, which is used as follows:\n\n$$\n  B y_{t} = y_{t - 1}\n$$\n\n. . .\n\nIn other words, $B$, operating on $y_{t}$, has the effect of **shifting the data back one period**. \n\n. . .\n\nTwo applications of $B$ to $y_{t}$ **shifts the data back two periods**:\n$$\n  B(By_{t}) = B^{2}y_{t} = y_{t-2}\n$$\n\n. . .\n\nFor monthly data, if we wish to shift attention to \"the same month last year\", then $B^{12}$ is used, and the notation is $B^{12}y_{t} = y_{t-12}$.\n\n## Backshift notation (2/4) \n\nThe backward shift operator is convenient for describing the process of *differencing*. \n\nA first-order difference can be written as\n$$\n  y'_{t} = y_{t} - y_{t-1} = y_t - By_{t} = (1 - B)y_{t}\n$$\n\n. . .\n\nSimilarly, if second-order differences (i.e., first differences of first differences) have to be computed, then:\n\n$$y''_{t} = y_{t} - 2y_{t - 1} + y_{t - 2} = (1 - B)^{2} y_{t}$$\n\n\n## Backshift notation (3/4) {.smaller}\n\n* Second-order difference is denoted $(1- B)^{2}$.\n* *Second-order difference* is not the same as a *second difference*, which would be denoted $1- B^{2}$;\n* In general, a $d$th-order difference can be written as\n\n. . .\n\n$$\n  (1 - B)^{d} y_{t}\n$$\n\n* A seasonal difference followed by a first difference can be written as\n\n. . .\n\n$$\n  (1-B)(1-B^m)y_t\n$$\n\n## Backshift notation (4/4) \n\nThe \"backshift\" notation is convenient because the terms can be multiplied together to see the combined effect.\n\n\\begin{align*}\n  (1-B)(1-B^m)y_t & = (1 - B - B^m + B^{m+1})y_t \\\\\n                  & = y_t-y_{t-1}-y_{t-m}+y_{t-m-1}.\n\\end{align*}\n\nFor monthly data, $m=12$ and we obtain the same result as earlier.\n\n# Non-seasonal ARIMA models\n\n## Autoregressive models {.smaller}\n\n**Autoregressive (AR) models:**\n\n$$\n  y_{t} = c + \\phi_{1}y_{t - 1} + \\phi_{2}y_{t - 2} + \\cdots + \\phi_{p}y_{t - p} + \\epsilon_{t},\n$$\nwhere $\\epsilon_t$ is white noise. This is a multiple regression with **lagged values** of $y_t$ as predictors.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/arp-1.png){width=960}\n:::\n:::\n\n\n\n\n## AR(1) model {.smaller}\n\n$y_{t} = 18 -0.8 y_{t - 1} + \\epsilon_{t},$ $\\epsilon_t\\sim N(0,1)$, $T=100$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-28-1.png){width=960}\n:::\n:::\n\n\n\n\n## AR(1) model {.smaller}\n\n\n$y_{t} = c + \\phi_1 y_{t - 1} + \\epsilon_{t}$\n\n\n* When $\\phi_1=0$, $y_t$ is **equivalent to WN**\n* When $\\phi_1=1$ and $c=0$, $y_t$ is **equivalent to a RW**\n* When $\\phi_1=1$ and $c\\ne0$, $y_t$ is **equivalent to a RW with drift**\n* When $\\phi_1<0$, $y_t$ tends to **oscillate between positive and negative values**.\n\n## AR(2) model\n\n$y_t = 8 + 1.3y_{t-1} - 0.7 y_{t-2} + \\epsilon_t$ where $\\epsilon_t\\sim N(0,1)$ & $T=100$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-29-1.png){width=960}\n:::\n:::\n\n\n\n\n## Stationarity conditions\n\nWe normally restrict autoregressive models to stationary data, and then some constraints on the values of the parameters are required.\n\n\\begin{block}{General condition for stationarity\n  Complex roots of $1-\\phi_1 z - \\phi_2 z^2 - \\dots - \\phi_pz^p$ lie outside the unit circle on the complex plane.\n\\end{block}\\pause\n\n* For $p=1$: $-1<\\phi_1<1$.\n* For $p=2$:\\newline $-1<\\phi_2<1\\qquad \\phi_2+\\phi_1 < 1 \\qquad \\phi_2 -\\phi_1 < 1$.\n* More complicated conditions hold for $p\\ge3$.\n* Estimation software takes care of this.\n\n## Moving Average (MA) models {.smaller}\n\n**Moving Average (MA) models:**\n\n$$\n  y_{t} = c + \\epsilon_t + \\theta_{1}\\varepsilon_{t - 1} + \\theta_{2}\\varepsilon_{t - 2} + \\cdots + \\theta_{q}\\varepsilon_{t - q},\n$$\n\nwhere $\\epsilon_t$ is white noise.\nThis is a multiple regression with **past *errors* ** as predictors. *Don't confuse this with moving average smoothing!*\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/maq-1.png){width=960}\n:::\n:::\n\n\n\n\n## MA(1) model\n\n$y_t = 20 + \\epsilon_t + 0.8 \\varepsilon_{t-1}$ where $\\epsilon_t\\sim N(0,1)$ & $T=100$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-30-1.png){width=960}\n:::\n:::\n\n\n\n\n## MA(2) model\n\n$y_t = \\epsilon_t -\\varepsilon_{t-1} + 0.8 \\varepsilon_{t-2}$ where $\\epsilon_t\\sim N(0,1)$ & $T=100$.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-31-1.png){width=960}\n:::\n:::\n\n\n\n\n## MA($\\infty$) models {.smaller}\n\nIt is possible to write any stationary AR($p$) process as an MA($\\infty$) process.\n\n**Example: AR(1)**\n\\begin{align*}\ny_t &= \\phi_1y_{t-1} + \\epsilon_t\\\\\n&= \\phi_1(\\phi_1y_{t-2} + \\varepsilon_{t-1}) + \\epsilon_t\\\\\n&= \\phi_1^2y_{t-2} + \\phi_1 \\varepsilon_{t-1} + \\epsilon_t\\\\\n&= \\phi_1^3y_{t-3} + \\phi_1^2\\varepsilon_{t-2} + \\phi_1 \\varepsilon_{t-1} + \\epsilon_t\\\\\n&\\dots\n\\end{align*}\nProvided $-1<\\phi_1<1$:\n$$y_t = \\epsilon_t + \\phi_1\\varepsilon_{t-1}+ \\phi_1^2\\varepsilon_{t-2}+ \\phi_1^3\\varepsilon_{t-3} + \\cdots$$\n\n## Invertibility\n\n* Any MA($q$) process can be written as an AR($\\infty$) process if we impose some constraints on the MA parameters.\n* Then the MA model is called \"invertible\".\n* Invertible models have some mathematical properties that make them easier to use in practice.\n\n## Invertibility\n\n**General condition for invertibility**\n  Complex roots of $1+\\theta_1 z + \\theta_2 z^2 + \\dots + \\theta_qz^q$ lie outside the unit circle on the complex plane.\n\n* For $q=1$: $-1<\\theta_1<1$.\n* For $q=2$:\\newline $-1<\\theta_2<1\\qquad \\theta_2+\\theta_1 >-1 \\qquad \\theta_1 -\\theta_2 < 1$.\n* More complicated conditions hold for $q\\ge3$.\n* Estimation software takes care of this.\n\n## ARMA models {.smaller}\n\n**Autoregressive Moving Average models:**\n\n$$y_{t} = c + \\phi_{1}y_{t - 1} + \\cdots + \\phi_{p}y_{t - p} + \\theta_{1}\\varepsilon_{t - 1} + \\cdots + \\theta_{q}\\varepsilon_{t - q} + \\epsilon_{t}.$$\n\n\n* Predictors include both **lagged values of $y_t$ and lagged errors.**\n* Conditions on AR coefficients ensure stationarity.\n* Conditions on MA coefficients ensure invertibility.\n\n## Autoregressive Integrated Moving Average models\n\n* Combine ARMA model with **differencing**.\n* $(1-B)^d y_t$ follows an ARMA model.\n\n## ARIMA models {.smaller}\n\n**Autoregressive Integrated Moving Average models**\n\n**ARIMA($p, d, q$) model**\n\n| **Component** | **Description**                             |\n|---------------|---------------------------------------------|\n| **AR**        | $p =$ order of the autoregressive part    |\n| **I**         | $d =$ degree of first differencing involved |\n| **MA**        | $q =$ order of the moving average part    |\n\n* White noise model: ARIMA(0,0,0)\n* Random walk: ARIMA(0,1,0) with no constant\n* Random walk with drift: ARIMA(0,1,0) with a constant (c)\n* AR($p$): ARIMA($p$,0,0)\n* MA($q$): ARIMA(0,0,$q$)\n\n## Backshift notation for ARIMA {.smaller}\n\n**ARMA model**\n\n$$\n\\begin{aligned}\ny_{t} &= c + \\phi_{1}By_{t} + \\cdots + \\phi_pB^py_{t}\n           + \\epsilon_{t} + \\theta_{1}B\\epsilon_{t} + \\cdots + \\theta_qB^q\\epsilon_{t} \\\\\n\\text{or}\\quad\n      & (1-\\phi_1B - \\cdots - \\phi_p B^p) y_t = c + (1 + \\theta_1 B + \\cdots + \\theta_q B^q)\\epsilon_t\n\\end{aligned}\n$$\n\n**ARIMA(1,1,1) model**\n\n$$\n\\begin{array}{c c c c}\n(1 - \\phi_{1} B) & (1 - B) y_{t} &= &c + (1 + \\theta_{1} B) \\epsilon_{t}\\\\\n{\\uparrow} & {\\uparrow} & &{\\uparrow}\\\\\n{\\text{AR(1)}} & {\\text{First}} &  &{\\text{MA(1)}}\\\\\n& \\text{difference}\\\\\n\\end{array}\n$$\n\n. . .\n\n$$\n  y_t = c + y_{t-1} + \\phi_1 y_{t-1}- \\phi_1 y_{t-2} + \\theta_1\\varepsilon_{t-1} + \\epsilon_t\n$$\n\n## General ARIMA Equation {.smaller}\n\n\n$$\n\\underbrace{(1 - \\phi_1 B - \\cdots - \\phi_p B^p)}_{\\text{AR}(p)}\n\\quad\n\\underbrace{(1 - B)^d}_{d \\text{ differences}}y_t = c+\n\\quad\n\\underbrace{(1 + \\theta_1 B + \\cdots + \\theta_q B^q)}_{\\text{MA}(q)}\\epsilon_t\n$$\n\n\n## R model {.smaller}\n\n**Intercept Form**\n\n$(1-\\phi_1B - \\cdots - \\phi_p B^p) y_t' = c + (1 + \\theta_1 B + \\cdots + \\theta_q B^q)\\epsilon_t$\n\n. . .\n\n**Mean Form**\n\n$(1-\\phi_1B - \\cdots - \\phi_p B^p)(y_t' - \\mu) = (1 + \\theta_1 B + \\cdots + \\theta_q B^q)\\epsilon_t$\n\n * $y_t' = (1-B)^d y_t$\n * $\\mu$ is the mean of $y_t'$.\n * $c = \\mu(1-\\phi_1 - \\cdots - \\phi_p )$.\n * `fable` uses the  intercept form\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Code == \"EGY\") |>\n  autoplot(Exports) +\n  labs(y = \"% of GDP\", title = \"Egyptian Exports\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/egyptexportsauto-1.png){width=960}\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- global_economy |> filter(Code == \"EGY\") |>\n  model(ARIMA(Exports))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Exports \nModel: ARIMA(2,0,1) w/ mean \n\nCoefficients:\n         ar1      ar2      ma1  constant\n      1.6764  -0.8034  -0.6896    2.5623\ns.e.  0.1111   0.0928   0.1492    0.1161\n\nsigma^2 estimated as 8.046:  log likelihood=-141.57\nAIC=293.13   AICc=294.29   BIC=303.43\n```\n\n\n:::\n:::\n\n\n\n\n\n\n## ARIMA(2,0,1) model:\n  \n$$\n  y_t = 2.56\n         + 1.68 y_{t-1}\n          -0.80 y_{t-2}\n          -0.69 \\varepsilon_{t-1}\n          + \\epsilon_{t},\n$$\n\nwhere $\\epsilon_t$ is white noise with a standard deviation of $2.837 = \\sqrt{8.046}$.\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-33-1.png){width=960}\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.innov, ljung_box, lag = 10, dof = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 4\n  Country          .model         lb_stat lb_pvalue\n  <fct>            <chr>            <dbl>     <dbl>\n1 Egypt, Arab Rep. ARIMA(Exports)    5.78     0.448\n```\n\n\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> forecast(h=10) |>\n  autoplot(global_economy) +\n  labs(y = \"% of GDP\", title = \"Egyptian Exports\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/egyptexportsf-1.png){width=960}\n:::\n:::\n\n\n\n\n## Understanding ARIMA models {.smaller}\n\nThe constant c has an important effect on the long-term forecasts obtained from these models.\n\n* If $c=0$ and $d=0$, the long-term forecasts will go to zero.\n* If $c=0$ and $d=1$, the long-term forecasts will go to a non-zero constant.\n* If $c=0$ and $d=2$, the long-term forecasts will follow a straight line.\n\n* If $c\\ne0$ and $d=0$, the long-term forecasts will go to the mean of the data.\n* If $c\\ne0$ and $d=1$, the long-term forecasts will follow a straight line.\n* If $c\\ne0$ and $d=2$, the long-term forecasts will follow a quadratic trend. (This is not recommended, and `fable` will not permit it.)\n\n\n\n## Understanding ARIMA models {.smaller}\n\n\n**Forecast variance and $d$**\n\n  * The higher the value of $d$, the more rapidly the prediction intervals increase in size.\n  * For $d=0$, the long-term forecast standard deviation will go to the standard deviation of the historical data.\n\n. . .\n\n**Cyclic behaviour**\n\n  * For cyclic forecasts, $p\\ge2$ and some restrictions on coefficients are required.\n  * If $p=2$, we need $\\phi_1^2+4\\phi_2<0$. Then average cycle of length $$(2\\pi)/\\left[\\text{arc cos}(-\\phi_1(1-\\phi_2)/(4\\phi_2))\\right].$$\n\n\n# Estimation and order selection\n\n## Maximum likelihood estimation {.smaller}\n\nHaving identified the model order, we need to estimate the parameters $c$, $\\phi_1,\\dots,\\phi_p$, $\\theta_1,\\dots,\\theta_q$.\n\n* MLE is very similar to least squares estimation obtained by minimizing\n\n. . .\n\n$$\n  \\sum_{t-1}^T e_t^2\n$$\n\n* The `ARIMA()` function allows LS or MLE estimation.\n* Non-linear optimization must be used in either case.\n* Different software will give different estimates.\n\n## Partial autocorrelations {.smaller}\n\n**Partial autocorrelations** measure relationship  \nbetween $y_{t}$ and $y_{t - k}$, when the effects of other time lags --- $1, 2, 3, \\dots, k - 1$ --- are removed.\\pause\n\n$$\n\\begin{aligned}\n\\alpha_k &= k\\text{th partial autocorrelation coefficient}\\\\\n         &= \\text{equal to the estimate of } \\phi_k \\text{ in regression:}\\\\\n         &  y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\dots + \\phi_k y_{t-k} + \\epsilon_t.\n\\end{aligned}\n$$\n\n* Varying number of terms on RHS gives $\\alpha_k$ for different values of $k$.\n* $\\alpha_1=\\rho_1$\n* same critical values of $\\pm 1.96/\\sqrt{T}$ as for ACF.\n* Last significant $\\alpha_k$ indicates the order of an AR model.\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\negypt <- global_economy |> filter(Code == \"EGY\")\negypt |> ACF(Exports) |> autoplot()\negypt |> PACF(Exports) |> autoplot()\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-36-1.png){width=960}\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |> filter(Code == \"EGY\") |>\n  gg_tsdisplay(Exports, plot_type='partial')\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-37-1.png){width=960}\n:::\n:::\n\n\n\n\n## ACF and PACF interpretation (1/4){.smaller}\n\n**AR(1)**\n\n$$\n\\begin{aligned}\n  \\rho_k &= \\phi_1^k \\text{ for } k=1,2,\\dots; \\\\\n  \\alpha_1 &= \\phi_1 \\\\\n  \\alpha_k &= 0 \\text{ for } k=2,3,\\dots.\n\\end{aligned}\n$$\n\nSo we have an AR(1) model when\n\n  * autocorrelations exponentially decay\n  * there is a single significant partial autocorrelation.\n\n## ACF and PACF interpretation (2/4){.smaller}\n\n**AR($p$)**\n\n  * ACF dies out in an exponential or damped sine-wave manner\n  * PACF has all zero spikes beyond the $p$th spike\n\n. . .\n\nSo we have an AR($p$) model when\n\n  * the ACF is exponentially decaying or sinusoidal\n  * there is a significant spike at lag $p$ in PACF, but none beyond $p$\n\n## ACF and PACF interpretation (3/4)\n\n**MA(1)**\n\n$$\n\\begin{aligned}\n\\rho_1 &= \\theta_1/(1 + \\theta_1^2) \\qquad \\rho_k = 0 \\qquad \\text{for } k=2,3,\\dots; \\\\\n\\alpha_k &= -(-\\theta_1)^k/(1 + \\theta_1^2 + \\dots + \\theta_1^{2k})\n\\end{aligned}\n$$\n\nSo we have an MA(1) model when\n\n* the PACF is exponentially decaying and\n* there is a single significant spike in ACF\n\n## ACF and PACF interpretation (4/4)\n\n**MA($q$)**\n\n* PACF dies out in an exponential or damped sine-wave manner\n* ACF has all zero spikes beyond the $q$th spike\n\n. . .\n\nSo we have an MA($q$) model when\n\n* the PACF is exponentially decaying or sinusoidal\n* there is a significant spike at lag $q$ in ACF, but none beyond $q$\n\n## Information criteria {.smaller}\n\n**Akaike's Information Criterion (AIC):**\n\n$$\n\\text{AIC} = -2 \\log(L) + 2(p+q+k+1),\n$$\n\nwhere $L$ is the likelihood of the data, $k=1$ if $c \\ne 0$ and $k=0$ if $c=0$.\\pause\n\n**Corrected AIC:**\n\n$$\n\\text{AICc} = \\text{AIC} + \\frac{2(p+q+k+1)(p+q+k+2)}{T-p-q-k-2}.\n$$\\pause\n\n**Bayesian Information Criterion:**\n\n$$\n\\text{BIC} = \\text{AIC} + \\log(T)-2.\n$$\n\n. . .\n\nGood models are obtained by minimizing either the AIC, **AICc** or **BIC**. Book authors' preference is to use the **AICc**.\n\n# ARIMA modelling in R\n\n## How does ARIMA() work? (1/7) {.smaller}\n\n**A non-seasonal ARIMA process**\n\n$$\n\\phi(B)(1-B)^d y_{t} = c + \\theta(B) \\epsilon_t\n$$\n\n. . .\n\nNeed to select appropriate orders: **$p, q, d$**\n\n. . .\n\n\n**Hyndman and Khandakar (JSS, 2008) algorithm:**\n\n* Select no. differences **$d$** and **$D$** via KPSS test and seasonal strength measure.\n* Select **$p, q$** by minimizing AICc.\n* Use stepwise search to traverse model space.\n\n## How does ARIMA() work? (2/7) {.smaller}\n\n**AICc Calculation**\n\n$$\n\\text{AICc} = -2 \\log(L) + 2(p+q+k+1)\\left[1 + \\frac{(p+q+k+2)}{T-p-q-k-2}\\right].\n$$\n\nwhere $L$ is the maximized likelihood fitted to the *differenced* data, $k=1$ if $c \\ne 0$ and $k=0$ otherwise.\n\n**Step 1:**\n\nSelect current model (with smallest AICc) from:\n\n- ARIMA$(2,d,2)$\n- ARIMA$(0,d,0)$\n- ARIMA$(1,d,0)$\n- ARIMA$(0,d,1)$\n\n## How does ARIMA() work? (3/7) {.smaller}\n\n**Step 2:**\n\nConsider variations of current model:\n- Vary one of $p, q$ from current model by $\\pm1$\n- $p, q$ both vary from current model by $\\pm1$\n- Include/exclude $c$ from current model\n\nModel with lowest AICc becomes current model.\n\n**Repeat Step 2 until no lower AICc can be found.**\n\n## How does ARIMA() work? (4/7) {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/ARMAgridsearch-1.png){width=60%}\n:::\n:::\n\n\n\n\n## How does ARIMA() work? (5/7) {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/ARMAgridsearch2-1.png){width=60%}\n:::\n:::\n\n\n\n\n## How does ARIMA() work? (6/7) {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/ARMAgridsearch3-1.png){width=60%}\n:::\n:::\n\n\n\n\n## How does ARIMA() work? (7/7) {.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/ARMAgridsearch4-1.png){width=60%}\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |> filter(Code == \"EGY\") |>\n  gg_tsdisplay(Exports, plot_type='partial')\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-38-1.png){width=960}\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <- global_economy |>\n  filter(Code == \"EGY\") |>\n  model(ARIMA(Exports ~ pdq(4,0,0)))\nreport(fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Exports \nModel: ARIMA(4,0,0) w/ mean \n\nCoefficients:\n         ar1      ar2     ar3      ar4  constant\n      0.9861  -0.1715  0.1807  -0.3283    6.6922\ns.e.  0.1247   0.1865  0.1865   0.1273    0.3562\n\nsigma^2 estimated as 7.885:  log likelihood=-140.53\nAIC=293.05   AICc=294.7   BIC=305.41\n```\n\n\n:::\n:::\n\n\n\n\n## Egyptian exports\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2 <- global_economy |>\n  filter(Code == \"EGY\") |>\n  model(ARIMA(Exports))\nreport(fit2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Exports \nModel: ARIMA(2,0,1) w/ mean \n\nCoefficients:\n         ar1      ar2      ma1  constant\n      1.6764  -0.8034  -0.6896    2.5623\ns.e.  0.1111   0.0928   0.1492    0.1161\n\nsigma^2 estimated as 8.046:  log likelihood=-141.57\nAIC=293.13   AICc=294.29   BIC=303.43\n```\n\n\n:::\n:::\n\n\n\n\n## Central African Republic exports (1/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Code == \"CAF\") |>\n  autoplot(Exports) +\n  labs(title=\"Central African Republic exports\", y=\"% of GDP\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-41-1.png){width=960}\n:::\n:::\n\n\n\n\n## Central African Republic exports (2/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_economy |>\n  filter(Code == \"CAF\") |>\n  gg_tsdisplay(difference(Exports), plot_type='partial')\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/caf2-1.png){width=960}\n:::\n:::\n\n\n\n\n## Central African Republic exports (3/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaf_fit <- global_economy |>\n  filter(Code == \"CAF\") |>\n  model(arima210 = ARIMA(Exports ~ pdq(2,1,0)),\n        arima013 = ARIMA(Exports ~ pdq(0,1,3)),\n        stepwise = ARIMA(Exports),\n        search = ARIMA(Exports, stepwise=FALSE))\n```\n:::\n\n\n\n\n## Central African Republic exports (4/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaf_fit |> pivot_longer(!Country, names_to = \"Model name\",\n                         values_to = \"Orders\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 4 x 3\n# Key:     Country, Model name [4]\n  Country                  `Model name`         Orders\n  <fct>                    <chr>               <model>\n1 Central African Republic arima210     <ARIMA(2,1,0)>\n2 Central African Republic arima013     <ARIMA(0,1,3)>\n3 Central African Republic stepwise     <ARIMA(2,1,2)>\n4 Central African Republic search       <ARIMA(3,1,0)>\n```\n\n\n:::\n:::\n\n\n\n\n## Central African Republic exports (5/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(caf_fit) |> arrange(AICc) |> select(.model:BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã 6\n  .model   sigma2 log_lik   AIC  AICc   BIC\n  <chr>     <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 search     6.52   -133.  274.  275.  282.\n2 arima210   6.71   -134.  275.  275.  281.\n3 arima013   6.54   -133.  274.  275.  282.\n4 stepwise   6.42   -132.  274.  275.  284.\n```\n\n\n:::\n:::\n\n\n\n\n## Central African Republic exports (6/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaf_fit |> select(search) |> gg_tsresiduals()\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/cafres-1.png){width=960}\n:::\n:::\n\n\n\n\n## Central African Republic exports (7/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(caf_fit) |>\n  filter(.model=='search') |>\n  features(.innov, ljung_box, lag = 10, dof = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 4\n  Country                  .model lb_stat lb_pvalue\n  <fct>                    <chr>    <dbl>     <dbl>\n1 Central African Republic search    5.75     0.569\n```\n\n\n:::\n:::\n\n\n\n\n## Central African Republic exports (8/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaf_fit |>\n  forecast(h=5) |>\n  filter(.model=='search') |>\n  autoplot(global_economy)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/caffc-1.png){width=960}\n:::\n:::\n\n\n\n\n## Modelling procedure with `ARIMA()` {.smaller}\n\n\n1. Plot the data. Identify any unusual observations.\n2. If necessary, transform the data (using a Box-Cox transformation) to stabilize the variance.\n3. If the data are non-stationary: take first differences of the data until the data are stationary.\n4. Examine the ACF/PACF: Is an AR($p$) or MA($q$) model appropriate?\n5. Try your chosen model(s), and use the *AICc* to search for a better model.\n6. Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.\n7. Once the residuals look like white noise, calculate forecasts.\n\n## Automatic modelling procedure with `ARIMA()` {.smaller}\n\n1. Plot the data. Identify any unusual observations.\n2. If necessary, transform the data (using a Box-Cox transformation) to stabilize the variance.\n\n. . .\n\n3. Use `ARIMA` to automatically select a model.\n\n. . .\n\n6. Check the residuals from your chosen model by plotting the ACF of the residuals, and doing a portmanteau test of the residuals. If they do not look like white noise, try a modified model.\n7. Once the residuals look like white noise, calculate forecasts.\n\n## Modelling procedure\n\n<iframe src=\"figs/figure_8_10.pdf\" width=\"100%\" height=\"600px\"></iframe>\n\n\n# Forecasting\n\n## Prediction intervals {.smaller}\n\n**95% prediction interval**\n\n$$\n\\hat{y}_{T+h|T} \\pm 1.96\\sqrt{v_{T+h|T}}\n$$\n\nwhere $v_{T+h|T}$ is estimated forecast variance.\n\n## Prediction intervals {.smaller}\n\nMulti-step prediction intervals for ARIMA(0,0,$q$):\n\n\n$$\ny_t = \\epsilon_t + \\sum_{i=1}^q \\theta_i \\varepsilon_{t-i}.\n$$\n\n$$\nv_{T|T+h} = \\hat{\\sigma}^2 \\left[ 1 + \\sum_{i=1}^{h-1} \\theta_i^2\\right], \\qquad \\text{for } h=2,3,\\dots.\n$$\n\n. . .\n\n* AR(1): Can be rewritten as MA($\\infty$) and use above result.\n* Other models beyond scope of this subject.\n\n## Prediction intervals {.smaller}\n\n* Prediction intervals **increase in size with forecast horizon**.\n* Prediction intervals can be difficult to calculate by hand\n* Calculations assume residuals are **uncorrelated** and **normally distributed**.\n* Prediction intervals tend to be too narrow.\n    * the uncertainty in the parameter estimates has not been accounted for.\n    * the ARIMA model assumes historical patterns will not change during the forecast period.\n    * the ARIMA model assumes uncorrelated future errors\n\n## Your turn\n\nFor the GDP data (from `global_economy`):\n\n * fit a suitable ARIMA model to the logged data for all countries\n * check the residual diagnostics for Australia;\n * produce forecasts of your fitted model for Australia.\n\n\n\n\n\n# Backshift notation revisited\n\n## Recall Backshift notation {.smaller}\n\nBackward shift operator, $B$, which is used as follows:\n$$\nB y_{t} = y_{t - 1} \\: .\n$$\n\n. . .\n\n$B$, operating on $y_{t}$, has the effect of **shifting the data back one period**.\n\n. . .\n\nFor monthly data, if we wish to shift attention to \"the same month last year,\" then $B^{12}$ is used, and the notation is $B^{12}y_{t} = y_{t-12}$.\n\n\n# Seasonal ARIMA models\n\n## Seasonal ARIMA models \n\n| ARIMA | $~\\underbrace{(p, d, q)}$ | $\\underbrace{(P, D, Q)_{m}}$ |\n| ----: | :-----------------------: | :--------------------------: |\n|       | ${\\uparrow}$              | ${\\uparrow}$                 |\n|       | Non-seasonal part         | Seasonal part of             |\n|       | of the model              | of the model                 |\n\nwhere $m =$ number of observations per year.\n\n## ARIMA$(1, 1, 1)(1, 1, 1)_{4}$ model (without constant) {.smaller}\n\n\n$$\n\\begin{aligned}\n&\\underbrace{(1 - \\phi_1 B)}_{\\text{Non-seasonal AR(1)} \\phantom{X}}\n\\underbrace{(1 - \\Phi_1 B^4)}_{\\text{Seasonal AR(1)} \\phantom{X}}\n\\underbrace{(1 - B)}_{\\text{Non-seasonal difference} \\phantom{X}}\n\\underbrace{(1 - B^4)}_{\\text{Seasonal difference} \\phantom{X}}\ny_t = \\\\\n&\\underbrace{(1 + \\theta_1 B)}_{\\text{Non-seasonal MA(1)} \\phantom{X}}\n\\underbrace{(1 + \\Theta_1 B^4)}_{\\text{Seasonal MA(1)} \\phantom{X}}\n\\varepsilon_t\n\\end{aligned}\n$$\n\n\n## Seasonal ARIMA models {.smaller}\n\nE.g., ARIMA$(1, 1, 1)(1, 1, 1)_{4}$ model (without constant)\n\n$$(1 - \\phi_{1}B)(1 - \\Phi_{1}B^{4}) (1 - B) (1 - B^{4})y_{t} =(1 + \\theta_{1}B) (1 + \\Theta_{1}B^{4})\\epsilon_{t}.$$\n\n\n## Common ARIMA models\n\nThe US Census Bureau uses the following models most often:\n\n| Model                        | Transformation          |\n|------------------------------|-------------------------|\n| ARIMA(0,1,1)(0,1,1)$_m$      | with log transformation |\n| ARIMA(0,1,2)(0,1,1)$_m$      | with log transformation |\n| ARIMA(2,1,0)(0,1,1)$_m$      | with log transformation |\n| ARIMA(0,2,2)(0,1,1)$_m$      | with log transformation |\n| ARIMA(2,1,2)(0,1,1)$_m$      | with no transformation  |\n\n## Seasonal ARIMA models {.smaller}\n\nThe seasonal part of an AR or MA model will be seen in the seasonal lags of\nthe PACF and ACF.\n\n**ARIMA(0,0,0)(0,0,1)$_{12}$ will show:**\n\n  * a spike at lag 12 in the ACF but no other significant spikes.\n  * The PACF will show exponential decay in the seasonal lags; that is, at lags 12, 24, 36, \\dots.\n\n. . .\n\n**ARIMA(0,0,0)(1,0,0)$_{12}$ will show:**\n\n  * exponential decay in the seasonal lags of the ACF\n  * a single significant spike at lag 12 in the PACF.\n\n## US leisure employment (1/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleisure <- us_employment |>\n  filter(Title == \"Leisure and Hospitality\", year(Month) > 2000) |>\n  mutate(Employed = Employed/1000) |>\n  select(Month, Employed)\nautoplot(leisure, Employed) +\n  labs(title = \"US employment: leisure & hospitality\", y=\"People (millions)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-42-1.png){width=960}\n:::\n:::\n\n\n\n\n## US leisure employment (2/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleisure |>\n  gg_tsdisplay(difference(Employed, 12), plot_type='partial', lag=36) +\n  labs(title=\"Seasonally differenced\", y=\"\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-43-1.png){width=960}\n:::\n:::\n\n\n\n\n## US leisure employment (3/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleisure |>\n  gg_tsdisplay(difference(Employed, 12) |> difference(),\n    plot_type='partial', lag=36) +\n  labs(title = \"Double differenced\", y=\"\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-44-1.png){width=960}\n:::\n:::\n\n\n\n\n## US leisure employment (4/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- leisure |>\n  model(\n    arima012011 = ARIMA(Employed ~ pdq(0,1,2) + PDQ(0,1,1)),\n    arima210011 = ARIMA(Employed ~ pdq(2,1,0) + PDQ(0,1,1)),\n    auto = ARIMA(Employed, stepwise = FALSE, approx = FALSE)\n  )\nfit |> pivot_longer(everything(), names_to = \"Model name\",\n                     values_to = \"Orders\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A mable: 3 x 2\n# Key:     Model name [3]\n  `Model name`                    Orders\n  <chr>                          <model>\n1 arima012011  <ARIMA(0,1,2)(0,1,1)[12]>\n2 arima210011  <ARIMA(2,1,0)(0,1,1)[12]>\n3 auto         <ARIMA(2,1,0)(1,1,1)[12]>\n```\n\n\n:::\n:::\n\n\n\n\n## US leisure employment (5/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(fit) |> arrange(AICc) |> select(.model:BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 Ã 6\n  .model       sigma2 log_lik   AIC  AICc   BIC\n  <chr>         <dbl>   <dbl> <dbl> <dbl> <dbl>\n1 auto        0.00142    395. -780. -780. -763.\n2 arima210011 0.00145    392. -776. -776. -763.\n3 arima012011 0.00146    391. -775. -775. -761.\n```\n\n\n:::\n:::\n\n\n\n\n## US leisure employment (6/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> select(auto) |> gg_tsresiduals(lag=36)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-47-1.png){width=960}\n:::\n:::\n\n\n\n\n## US leisure employment (7/8)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |> features(.innov, ljung_box, lag=24, dof=4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 Ã 3\n  .model      lb_stat lb_pvalue\n  <chr>         <dbl>     <dbl>\n1 arima012011    22.4     0.320\n2 arima210011    18.9     0.527\n3 auto           16.6     0.680\n```\n\n\n:::\n:::\n\n\n\n\n## US leisure employment (8/8)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforecast(fit, h=36) |>\n  filter(.model=='auto') |>\n  autoplot(leisure) +\n  labs(title = \"US employment: leisure and hospitality\", y=\"Number of people (millions)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-49-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (1/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 <- PBS |>\n  filter(ATC2 == \"H02\") |>\n  summarise(Cost = sum(Cost)/1e6)\n```\n:::\n\n\n\n\n## Cortecosteroid drug sales (2/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  Cost\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-51-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (3/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  log(Cost)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-52-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (4/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> autoplot(\n  log(Cost) |> difference(12)\n)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-53-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (5/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nh02 |> gg_tsdisplay(difference(log(Cost),12),\n                 lag_max = 36, plot_type = 'partial')\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/h02b-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (6/20)\n\n  * Choose $D=1$ and $d=0$.\n  * Spikes in PACF at lags 12 and 24 suggest seasonal AR(2) term.\n  * Spikes in PACF suggests possible non-seasonal AR(3) term.\n  * Initial candidate model: ARIMA(3,0,0)(2,1,0)$_{12}$.\n\n## Cortecosteroid drug sales  (7/20){.smaller}\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|         .model          |  AICc   |\n|:-----------------------:|:-------:|\n| ARIMA(3,0,1)(0,1,2)[12] | -485.48 |\n| ARIMA(3,0,1)(1,1,1)[12] | -484.25 |\n| ARIMA(3,0,1)(0,1,1)[12] | -483.67 |\n| ARIMA(3,0,1)(2,1,0)[12] | -476.31 |\n| ARIMA(3,0,0)(2,1,0)[12] | -475.12 |\n| ARIMA(3,0,2)(2,1,0)[12] | -474.88 |\n| ARIMA(3,0,1)(1,1,0)[12] | -463.40 |\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (8/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- h02 |>\n  model(best = ARIMA(log(Cost) ~ 0 + pdq(3,0,1) + PDQ(0,1,2)))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Cost \nModel: ARIMA(3,0,1)(0,1,2)[12] \nTransformation: log(Cost) \n\nCoefficients:\n          ar1     ar2     ar3     ma1     sma1     sma2\n      -0.1603  0.5481  0.5678  0.3827  -0.5222  -0.1768\ns.e.   0.1636  0.0878  0.0942  0.1895   0.0861   0.0872\n\nsigma^2 estimated as 0.004278:  log likelihood=250.04\nAIC=-486.08   AICc=-485.48   BIC=-463.28\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (9/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/h02res-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (10/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.innov, ljung_box, lag = 36, dof = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 best      50.7    0.0104\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (11/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- h02 |> model(auto = ARIMA(log(Cost)))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Cost \nModel: ARIMA(2,1,0)(0,1,1)[12] \nTransformation: log(Cost) \n\nCoefficients:\n          ar1      ar2     sma1\n      -0.8491  -0.4207  -0.6401\ns.e.   0.0712   0.0714   0.0694\n\nsigma^2 estimated as 0.004387:  log likelihood=245.39\nAIC=-482.78   AICc=-482.56   BIC=-469.77\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (12/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-54-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (13/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.innov, ljung_box, lag = 36, dof = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 auto      59.3   0.00332\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (14/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- h02 |>\n  model(best = ARIMA(log(Cost), stepwise = FALSE,\n                 approximation = FALSE,\n                 order_constraint = p + q + P + Q <= 9))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Cost \nModel: ARIMA(4,1,1)(2,1,2)[12] \nTransformation: log(Cost) \n\nCoefficients:\n          ar1     ar2     ar3      ar4      ma1    sar1     sar2     sma1    sma2\n      -0.0425  0.2098  0.2017  -0.2273  -0.7424  0.6213  -0.3832  -1.2019  0.4959\ns.e.   0.2167  0.1813  0.1144   0.0810   0.2074  0.2421   0.1185   0.2491  0.2135\n\nsigma^2 estimated as 0.004049:  log likelihood=254.31\nAIC=-488.63   AICc=-487.4   BIC=-456.1\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (15/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/unnamed-chunk-56-1.png){width=960}\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (16/20)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(fit) |>\n  features(.innov, ljung_box, lag = 36, dof = 9)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 best      36.5     0.106\n```\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (17/20){.smaller}\n\n\nTraining data: July 1991 to June 2006\n\nTest data: July 2006--June 2008\n\n```r\nfit <- h02 |>\n  filter_index(~ \"2006 Jun\") |>\n  model(\n    ARIMA(log(Cost) ~ 0 + pdq(3, 0, 0) + PDQ(2, 1, 0)),\n    ARIMA(log(Cost) ~ 0 + pdq(3, 0, 1) + PDQ(2, 1, 0)),\n    ARIMA(log(Cost) ~ 0 + pdq(3, 0, 2) + PDQ(2, 1, 0)),\n    ARIMA(log(Cost) ~ 0 + pdq(3, 0, 1) + PDQ(1, 1, 0))\n    # ... #\n  )\n\nfit |>\n  forecast(h = \"2 years\") |>\n  accuracy(h02)\n```\n\n## Cortecosteroid drug sales (18/20){.smaller}\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.model                  |   RMSE|\n|:-----------------------|------:|\n|ARIMA(3,0,1)(1,1,1)[12] | 0.0619|\n|ARIMA(3,0,1)(0,1,2)[12] | 0.0621|\n|ARIMA(3,0,1)(0,1,1)[12] | 0.0630|\n|ARIMA(2,1,0)(0,1,1)[12] | 0.0630|\n|ARIMA(4,1,1)(2,1,2)[12] | 0.0631|\n|ARIMA(3,0,2)(2,1,0)[12] | 0.0651|\n|ARIMA(3,0,1)(2,1,0)[12] | 0.0653|\n|ARIMA(3,0,1)(1,1,0)[12] | 0.0666|\n|ARIMA(3,0,0)(2,1,0)[12] | 0.0668|\n\n\n:::\n:::\n\n\n\n\n## Cortecosteroid drug sales (19/20)\n\n  * Models with lowest AICc values tend to give slightly better results than the other models.\n  * AICc comparisons must have the same orders of differencing. But RMSE test set comparisons can involve any models.\n  * Use the best model available, even if it does not pass all tests.\n\n## Cortecosteroid drug sales (20/20)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- h02 |>\n  model(ARIMA(Cost ~ 0 + pdq(3,0,1) + PDQ(0,1,2)))\nfit |> forecast() |> autoplot(h02) +\n  labs(y = \"H02 Expenditure ($AUD)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/h02f-1.png){width=960}\n:::\n:::\n\n\n\n\n# ARIMA vs ETS\n\n## ARIMA vs ETS {.smaller}\n\n\n  * Myth that ARIMA models are more general than exponential smoothing.\n  * Linear exponential smoothing models all special cases of ARIMA models.\n  * Non-linear exponential smoothing models have no equivalent ARIMA counterparts.\n  * Many ARIMA models have no exponential smoothing counterparts.\n  * ETS models all non-stationary. Models with seasonality or non-damped trend (or both) have two unit roots; all other models have one unit **root.**\n\n\n\n## ARIMA vs ETS\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/venn-1.png){width=960}\n:::\n:::\n\n\n\n\n## Equivalences {.smaller}\n\n\n\n|**ETS model**  | **ARIMA model**             | **Parameters**                       |\n| :------------ | :-------------------------- | :----------------------------------- |\n| ETS(A,N,N)    | ARIMA(0,1,1)                | $\\theta_1 = \\alpha-1$                |\n| ETS(A,A,N)    | ARIMA(0,2,2)                | $\\theta_1 = \\alpha+\\beta-2$          |\n|               |                             | $\\theta_2 = 1-\\alpha$                |\n| ETS(A,A\\damped,N)    | ARIMA(1,1,2)                | $\\phi_1=\\phi$                        |\n|               |                             | $\\theta_1 = \\alpha+\\phi\\beta-1-\\phi$ |\n|               |                             | $\\theta_2 = (1-\\alpha)\\phi$          |\n| ETS(A,N,A)    | ARIMA(0,0,$m$)(0,1,0)$_m$   |                                      |\n| ETS(A,A,A)    | ARIMA(0,1,$m+1$)(0,1,0)$_m$ |                                      |\n| ETS(A,A\\damped,A)    | ARIMA(1,0,$m+1$)(0,1,0)$_m$ |                                      |\n\n## Example: Australian population\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_economy <- global_economy |> filter(Code == \"AUS\") |>\n  mutate(Population = Population/1e6)\naus_economy |>\n  slice(-n()) |>\n  stretch_tsibble(.init = 10) |>\n  model(ets = ETS(Population),\n        arima = ARIMA(Population)\n  ) |>\n  forecast(h = 1) |>\n  accuracy(aus_economy) |>\n  select(.model, ME:RMSSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã 8\n  .model     ME   RMSE    MAE   MPE  MAPE  MASE RMSSE\n  <chr>   <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>\n1 arima  0.0420 0.194  0.0789 0.277 0.509 0.317 0.746\n2 ets    0.0202 0.0774 0.0543 0.112 0.327 0.218 0.298\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Australian population\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naus_economy |>\n  model(ETS(Population)) |>\n  forecast(h = \"5 years\") |>\n  autoplot(aus_economy) +\n  labs(title = \"Australian population\",  y = \"People (millions)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/popetsplot-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Cement production (1/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncement <- aus_production |>\n  select(Cement) |>\n  filter_index(\"1988 Q1\" ~ .)\ntrain <- cement |> filter_index(. ~ \"2007 Q4\")\nfit <- train |>\n  model(\n    arima = ARIMA(Cement),\n    ets = ETS(Cement)\n  )\n```\n:::\n\n\n\n\n## Example: Cement production (2/9)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(arima) |>\n  report()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Cement \nModel: ARIMA(1,0,1)(2,1,1)[4] w/ drift \n\nCoefficients:\n         ar1      ma1   sar1     sar2     sma1  constant\n      0.8886  -0.2366  0.081  -0.2345  -0.8979    5.3884\ns.e.  0.0842   0.1334  0.157   0.1392   0.1780    1.4844\n\nsigma^2 estimated as 11456:  log likelihood=-463.52\nAIC=941.03   AICc=942.68   BIC=957.35\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Cement production (3/9)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |> select(ets) |> report()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Cement \nModel: ETS(M,N,M) \n  Smoothing parameters:\n    alpha = 0.7533714 \n    gamma = 0.0001000093 \n\n  Initial states:\n     l[0]     s[0]    s[-1]    s[-2]     s[-3]\n 1694.712 1.031179 1.045209 1.011424 0.9121874\n\n  sigma^2:  0.0034\n\n     AIC     AICc      BIC \n1104.095 1105.650 1120.769 \n```\n\n\n:::\n:::\n\n\n\n\n## Example: Cement production (4/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit |> select(arima), lag_max = 16)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/qcement4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Cement production (5/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_tsresiduals(fit |> select(ets), lag_max = 16)\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/qcement5-1.png){width=960}\n:::\n:::\n\n\n\n\n## Example: Cement production (6/9)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(arima) |>\n  augment() |>\n  features(.innov, ljung_box, lag = 16, dof = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 arima     6.37     0.783\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Cement production (7/9)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(ets) |>\n  augment() |>\n  features(.innov, ljung_box, lag = 16, dof = 6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 Ã 3\n  .model lb_stat lb_pvalue\n  <chr>    <dbl>     <dbl>\n1 ets       10.0     0.438\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Cement production (8/9)\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  forecast(h = \"2 years 6 months\") |>\n  accuracy(cement) |>\n  select(-ME, -MPE, -ACF1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã 7\n  .model .type  RMSE   MAE  MAPE  MASE RMSSE\n  <chr>  <chr> <dbl> <dbl> <dbl> <dbl> <dbl>\n1 arima  Test   216.  186.  8.68  1.27  1.26\n2 ets    Test   222.  191.  8.85  1.30  1.29\n```\n\n\n:::\n:::\n\n\n\n\n## Example: Cement production (9/9)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit |>\n  select(arima) |>\n  forecast(h=\"3 years\") |>\n  autoplot(cement) +\n  labs(title = \"Cement production in Australia\", y=\"Tonnes ('000)\")\n```\n\n::: {.cell-output-display}\n![](9-arima_files/figure-revealjs/qcement9-1.png){width=960}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}